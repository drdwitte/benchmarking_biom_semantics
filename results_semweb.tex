%
%RESULTS Rev1: Notebook Rev1_13 - A Median & Average Runtime
%median/mean
%LdF_N1_64_W100_Def     19.949113	64.842078
%LdF_N3_64_W100_Def     58.365978 	122.960265
%LdF_N1_64_W1000_Def    300.0		219.935204
%LdF_N3_64_W1000_Def    300.0		216.525390
%
%RESULTS Rev1: Notebook Rev1_13 - B Errors & Timeout percentage
%Fus_N1_64_W100_Def:	Success: 65.0	Error: 0.0	Timeout: 34.9
%FedX_N3_64_W100_Def:	Success: 0.0	Error: 0.0	Timeout: 0.0
%LdF_N1_64_W100_Def:	Success: 89.0	Error: 0.0	Timeout: 10.9
%LdF_N3_64_W100_Def:	Success: 75.2	Error: 0.0	Timeout: 24.7
%
%Fus_N1_64_W1000_Def:	Success: 0.0	Error: 0.0	Timeout: 0.0
%FedX_N1_64_W1000_Def:	Success: 95.0	Error: 0.0	Timeout: 5.0
%FedX_N3_64_W1000_Def:	Success: 0.0	Error: 0.0	Timeout: 0.0
%LdF_N1_64_W1000_Def:	Success: 28.8	Error: 0.0	Timeout: 71.1
%LdF_N3_64_W1000_Def:	Success: 29.3	Error: 0.0	Timeout: 70.6
%

%As the initial goal of the research collaboration with Ontoforce was to find a solution to work with federated querying on top of live data sources on the Semantic Web, 
In this section we discuss the results of \textbf{Fus1\_64}, \textbf{FedX3\_64}, \textbf{TPF1\_64}, and \textbf{TPF3\_64}. 
For these 3 systems engine failure and query errors are very common with only the \textbf{TPF*\_64} systems surviving the entire benchmark.
Fig.~\ref{fig:Fig03_BenchmarkSurvival_Other_Watdiv_Default} shows the \emph{Benchmark Survival Interval}, defined as the range between the first and the last successful query. 
Given the high degree of failures we do not show the query runtime results.
%Note however that these results do not affect the plots as we only use query events from the \emph{benchmark survival interval}. 
%Fig. deliberately has no relation with query runtimes. 

%Benchmark Survival
%Finally, a subtle error can be made in query runtime comparison for benchmarks which involve a query engine that becomes unresponsive (engine failure). In the runtime comparisons we only consider  We name this the \emph{benchmark survival interval}, this is shown in Figure~\ref{fig:Fig03_BenchmarkSurvival_Other_Watdiv_Default}.

\begin{itemize}
	\item \textbf{FedX1\_64:} This single-node setup is tested to verify whether FedX manages to parse the queries. As the queries have the same form for WatDiv100M, we only tested this in the 1000M setting.
	\item \textbf{Specific Templates cause crashes:} Where \\ \textbf{TPF*\_64} systems more gracefully timeout on the \textbf{C} templates, \textbf{C2} causes a crash in \textbf{Fus1\_64} and \textbf{C3} in \textbf{FedX3\_64}, upon their first occurrence in warm-up or stress run. \textbf{C3} is a query with very low triple pattern selectivity leading to large in-memory joins.
	\item \textbf{Crash investigation:} For \textbf{FedX3\_64} the benchmark was terminated after running into constant timeouts for 8 hours. Inspection of the slave nodes showed them to be idle, while the federator node had its entire memory pool saturated, with the CPU load close to zero. This might be related to issues with garbage collection.
	For \textbf{Fus1\_64} after a number of queries a continuous timeout sequence sets in. The specific HDT implementation for Fuseki ignores the timeout parameter. This might explain why the server became unresponsive.
	\item \textbf{Staying alive:} \textbf{TPF*\_64} survive both WatDiv benchmarks, nonetheless with up to 71\% of the queries timeouts on WatDiv1000M. On WatDiv100M the timeout ratio drops to 25\% for \textbf{TPF3\_64} and to 11\% for \textbf{TPF1\_64}.
%Fus_N1_64_W100_Def:	Success: 65.0	Error: 0.0	Timeout: 34.9
%FedX_N3_64_W100_Def:	Success: 0.0	Error: 0.0	Timeout: 0.0
%LdF_N1_64_W100_Def:	Success: 89.0	Error: 0.0	Timeout: 10.9
%LdF_N3_64_W100_Def:	Success: 75.2	Error: 0.0	Timeout: 24.7
%
%Fus_N1_64_W1000_Def:	Success: 0.0	Error: 0.0	Timeout: 0.0
%FedX_N1_64_W1000_Def:	Success: 95.0	Error: 0.0	Timeout: 5.0
%FedX_N3_64_W1000_Def:	Success: 0.0	Error: 0.0	Timeout: 0.0
%LdF_N1_64_W1000_Def:	Success: 28.8	Error: 0.0	Timeout: 71.1
%LdF_N3_64_W1000_Def:	Success: 29.3	Error: 0.0	Timeout: 70.6
	\item \textbf{Runtime Comparison: } Only for WatDiv100M comparing the runtimes of \textbf{TPF*\_64} to the \emph{Vendor} systems is meaningful due to the higher query success rates. Compared to \textbf{ES1\_32}, the \textbf{TPF1\_64} is 2.4 times faster in terms of median runtime and 12\% in terms of average runtime. For \textbf{TPF3\_64} the results are worse than \textbf{ES1\_32}: 25\% slower in median runtime, 40\% slower for average runtime.
\end{itemize}
%Bla_N1_32_W100_Def   0.191359		0.461707
%Gra_N1_32_W100_Def   0.047812		0.417214
%Es_N1_32_W100_Def    48.305706		72.994550
%Vir_N1_32_W100_Def   0.046707		0.301350
%LdF_N1_64_W100_Def     19.949113	64.842078
%LdF_N3_64_W100_Def     58.365978 	122.960265









