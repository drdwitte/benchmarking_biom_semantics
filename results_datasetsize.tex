%
%RESULTS Rev1: Notebook Rev1_13 -s A Median & Average Runtime
%RESULTS Rev1: Notebook Rev1_13 - B Errors & Timeout percentage
%
In this section we use the \emph{Documented} configuration of the \emph{Vendor} systems.
Figure~\ref{fig:Fig01_WatdivNoSQLDataScaling} shows query runtime distributions for the four \emph{Vendor} systems for three different dataset sizes of the WatDiv benchmark: 10M, 100M, and 1000M (million) triples. These benchmarks were run on a node with 32 GB of memory.
%
%median/mean
%Bla_N1_32_W10_Def    0.033637		0.058546
%Gra_N1_32_W10_Def    0.007062		0.036882
%Es_N1_32_W10_Def     0.163703		0.290875
%Vir_N1_32_W10_Def    0.007511		0.018063
%
%Bla_N1_32_W100_Def   0.191359		0.461707
%Gra_N1_32_W100_Def   0.047812		0.417214
%Es_N1_32_W100_Def    48.305706		72.994550
%Vir_N1_32_W100_Def   0.046707		0.301350
%  
%Bla_N1_32_W1000_Def  8.858862 		56.437824
%Gra_N1_32_W1000_Def  47.932701 	74.927924
%Es_N1_32_W1000_Def   64.217677 	121.887237
%Vir_N1_32_W1000_Def  0.258209  	5.622635
%speedups
%Bla		7.8862262153 		122.2373150071
%Gra		11.3121305786 		179.5911067222
%Es			250.9481736141 		1.6698128422
%Vir		16.6832752035 		18.6581549693

\begin{itemize}
	\item \textbf{Runtime vs.\ Dataset Size:} It is interesting to investigate how the runtime scales when the dataset grows by a factor 10. The average query runtimes (dots) reveal two trends: \textbf{Vir1\_32} has a nearly constant multiplication factor (MF) whereas for the other stores this is not the case: from 10M to 100M the MFs are 8, 11, and 17 for \textbf{Bla1\_32}, \textbf{Gra1\_32}, and \textbf{Vir1\_32} respectively; from 100M to 1000M the MF for \textbf{Vir1\_32} is 19, but for the other systems MF $> 120$. A possible explanation is that memory swapping occurs. This observation motivates the choice for 64GB memory instances as the central reference setup.
%errors and timeouts
%Bla_N1_32_W1000_Def:	Success: 88.3	Error: 0.0	Timeout: 11.6
%Gra_N1_32_W1000_Def:	Success: 100.	Error: 0.0	Timeout: 0.0
%Es_N1_32_W1000_Def:	Success: 67.2	Error: 0.0	Timeout: 32.7
%Vir_N1_32_W1000_Def:	Success: 99.9	Error: 0.04	Timeout: 0.0
\item \textbf{Timeouts \& Errors:} Most of the queries are executed successfully by all \emph{Vendor} systems. However, using WatDiv1000M, 11.6\% of the queries result in a timeout for \textbf{Bla1\_32}  and for \textbf{ES1\_32} this is even 32.7\%. 

\item \textbf{GraphDB vs.\ Virtuoso:} In terms of median runtime both \textbf{Gra1\_32} and \textbf{Vir1\_32} are tied at 0.01s and 0.05s in the two leftmost panels of Fig.~\ref{fig:Fig01_WatdivNoSQLDataScaling}. With sufficient memory these engines remain competitive. However, for 1000M dataset only \textbf{Vir1\_32} is performing well. %, with an increase in median runtime with a factor of 18.6 compared to 100M run while the median runtimes of the other stores increase with a factor of 100 or more. 
\textbf{Gra1\_32} suffers from a long tail which has a major effect on the average runtimes for WatDiv10M and 100M. Based on these runtimes, Virtuoso is 1.5-2 times faster.

\item \textbf{Blazegraph vs.\ GraphDB:} \textbf{Bla1\_32} competes with \textbf{Gra1\_32} in terms of average runtimes but not in terms of median runtimes.

\item \textbf{ES is consistently slowest:} \textbf{ES1\_32}, even on WatDiv10M, lags by a factor of at least 5 to the other systems. For WatDiv100M already the nonlinear scaling behavior sets in, making it the only engine to experience problems with the 100M dataset. 
\end{itemize}
%
