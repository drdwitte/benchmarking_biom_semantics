
We created a Feature Matrix and evaluated a number of stores on a subset of those features (a similar approach as in Stegmaier~\cite{Stegmaier_evaluationof}) to make a preselection of RDF engines.
We combined two ideas to create a Feature Matrix, to simplify the RDF store selection process:
\begin{itemize}
\item We consulted the DB-Engines ranking~\cite{dbengines}, which orders database systems according to their data model and online popularity, as measured by the mentions on social platforms such as StackOverflow, Twitter, and LinkedIn. 
DB-Engines also supports comparing multiple features of different systems.
\item WikiData selected the most appropriate RDF store to host their data by having experts assign weights to desired features~\cite{wikidataranking}.
These weights allowed them to calculate a score per data store and rank the different systems. 
\end{itemize}

The feature matrix contains a broad selection of suitable features specific for RDF engines and allows for multi-way comparisons. Engines are ranked by assigning weights to these features. 
The feature matrix is available online (see \textbf{Additional File 1 -- Feature Matrix}), and can be freely downloaded and extended. To back the scoring, we added a layer of trust by linking to the source of information.
The criteria for selection of the \emph{Vendor} systems are the following:
SPARQL 1.1 compliance, systems with a machine or maintained Docker image, no restrictions on the number of triples that can be ingested, and support for multi-node deployment.
% allegrograph en stardog vallen hierdoor  af
This led to 4 \emph{Vendor} systems: Blazegraph, GraphDB, ES and Virtuoso.
Additionally, we added 3 additional research \emph{Prototypes} with unique approaches to handling RDF data: HDT~\cite{DBLP:journals/ws/FernandezMGPA13}, which is a queryable read-only binary compression format, FedX~\cite{DBLP:conf/semweb/SchwarteHHSS11} often included in benchmarks for federated querying, and Triple Pattern Fragments~\cite{DBLP:conf/semweb/VerborghHMHVSCCMW14} as a first implementation of the Linked Data Fragments concept.

%The comparison with these \emph{Prototypes} was an essential part of the research collaboration with Ontoforce as their initial goal was to build their DISQOVER search interface on top of a federated querying system.
%The advantage of the latter is that their interface would then provide a live view on a continuously updating Life Sciences Linked Data cloud, removing the need for an ETL~\cite{ETL} process. The HDT-format is an interesting approach to provide their customers with a low-cost approach for hosting their own data.

Selected stores are shown in Table~\ref{acronyms} together with their shorthand notation.

\begin{table}[ht!]
	\centering
	%\processtable{Overview of the datasets used in the performance tests.\label{Tab:01}}
	\caption{List of the tested systems and their acronyms.}
	\label{acronyms}
	\scalebox{0.99}{
	\begin{tabular}{l|l}
		\hline
		\textbf{System} & \textbf{Shorthand} \\
		\hline
		Blazegraph 2.1.2              & \textbf{Bla}     \\
		Undisclosed Enterprise  Store & \textbf{ES}      \\
		GraphDB 7.0.1                 & \textbf{Gra}     \\
		Virtuoso 7.2.42               & \textbf{Vir}     \\
		\hline
		FluidOps~\cite{fluidops} (with FedX 3.1.2~\cite{DBLP:conf/semweb/SchwarteHHSS11})    & \textbf{FedX}     \\
		HDT-Fuseki 4.0.0~\cite{hdtfuseki}: Jena Fuseki \\
		to query HDT                     & \textbf{Fus}     \\
		Triple Pattern Fragments: Server.js 2.2~\cite{ldfserver},      & \textbf{TPF} \\
		Client.js 2.0~\cite{ldfclient}  & \\
		
		\hline
	\end{tabular}
	}
	%\caption*{The first four stores are \emph{Vendor} systems, the last three are \emph{SemWeb systems}}

\end{table}


%Our initial results with the 4 \emph{Vendor} systems showed large differences in runtime performance~\cite{de2016big}. After consulting with the database vendors, it turned out that this can be attributed to our choice of running the systems as-is. 

We run the benchmarks using two strictly defined configurations: \emph{Documented} and \emph{RFI-optimized}.  

The \emph{Documented} configuration corresponds to the recommended settings from the vendor
documentation, which takes into account the available server memory and the dataset size.
The \emph{RFI-Optimized} configuration was obtained after sending out a  Request For Information (RFI) to the commercial vendors involved. The RFI asked them to provide us with scripts or configuration files to achieve optimal performance on the WatDiv1000M benchmark. GraphDB, Virtuoso, and Blazegraph responded positively to this request. A fourth commercial vendor, ES, did not respond to our RFI. 
Note that this configuration is not necessarily an optimal match for the real-world benchmark, as the data and queries were not shared with the vendors.

%\begin{table}[htbp!]
%	\centering
%	\caption{Different configuration choices defined in this benchmark}
%	\label{table:configs}
%	\scalebox{0.9}{
%		\begin{tabular}{l|l}
%			\hline
%			\textbf{Name} & \textbf{Description} \\
%			\hline
%			\emph{Recommended} & Applying the \todo{ \\
%			\emph{Optimized} & Settings provided by the vendors, in response to our RFI.  \\
%			\hline
%		\end{tabular}
%	}
%\end{table}
%\todo{Tot hier}