%runtimes: median - mean - response
In this section we study the query runtime distributions of different Linked Data systems. 
In Table~\ref{table:namingconv} we introduce a naming convention to describe the different benchmark setups. 

Each query is executed six times: once as a warmup run and five times as a stress test. The \emph{query runtime} is defined as the median value of these five different measurements.
When aggregating runtimes over \emph{different queries}, for example when aggregating per query template, we report both the \emph{median} and \emph{mean query runtimes}. 

%As the runtime distributions can be skewed, performance differences between systems are most often reported using the median runtime of an aggregate or benchmark run. 
%If we consider an ETL process, or equivalently a batch of queries, the mean runtime becomes more meaningful, as it directly translates to the total runtime of an aggregate or full run. In the following box plots we chose to report both.



\begin{table}[ht!]
	\centering
	\caption{Conventions for describing benchmark setups.}
	\label{table:namingconv}
	\scalebox{0.9}{
		\begin{tabular}{l|l}
			\hline
			\textbf{Shorthand} & \textbf{Full Description} \\
			\textbf{Notation}	& \; \\
			\hline
			\textbf{Vir1\_32\_Doc}                  & Virtuoso - single node - 32GB RAM - \\
			& Documented Configuration\\
			\textbf{TPF3\_64\_Doc}                  & Triple Pattern Fragments - 3 slave nodes - 64GB RAM - \\
			& Documented Configuration\\
			\textbf{Gra1\_64\_RFI}                  & GraphDB - single node - 64GB RAM - \\
			& RFI-Optimized Configuration\\
			\hline
		\end{tabular}
	}
	 \caption*{A description consists of a 3-character prefix describing the RDF storage solution, the number of nodes, the amount of memory and the configuration.}
\end{table}




\subsection{Runtime Performance for Different Dataset Scales}
\label{subsec:bigdata}
\input{results_datasetsize.tex}

\subsection{Vertical Scaling}
\label{subsec:vscaling}
\input{results_verticalscaling.tex}

\subsection{RFI-Optimized Configuration}
\label{subsec:rfi}
\input{results_optimized.tex}

\subsection{Research Prototypes}
\label{subsec:semweb}
\input{results_semweb.tex}

\subsection{Horizontal scaling}
\label{subsec:hscaling}
\input{results_horizontalscaling.tex}

\subsection{Query Response Times}
%response times
Query response times correspond to the lag between sending a query and receiving the first server response. Some of the stores provide query results in a streaming fashion, 
therefore response times can be different from query runtimes.
%Response times are not captured in the current query event format but are captured in the SPARQL benchmarker summary CSV-files. 
For GraphDB and Blazegraph the response times are respectively 27\% and 21\% lower than the mean runtimes on WatDiv1000M. For the other engines the difference was close to zero.
%N1_64_Opt WatDiv 1000M: 
%Store 			Avg Mix Response 	Avg Mix Runtime
%Blazegraph: 	7436.614781577 		9361.074445217   	=> 1925 sneller = 21% lager
%Es 			45543.319632289	    45548.207560219  	=> coincide
%GraphDB   		6095.473343756 		8377.37145798 		=> 2282 sneller = 27% lager
%Virtuoso       1984.603994124	    2021.146539186		=> coincide
% LdF1 en LDF3 	












