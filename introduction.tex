%put back Ruben's first version
%which ~ by the way moet erbij kunnen. which voor extra info, maar bij aanwijzing moet THAT

The vision of the \emph{Semantic Web} is to serve as a global distributed database which can be autonomously explored by intelligent agents. The Linked Open Data (LOD) project~\cite{bizer2007interlinking} is an implementation of this vision and already contains over 1,000 interconnected datasets in Resource Description Framework (RDF) format. 
Semantic Web technology has a lot to offer to multidisciplinary research domains.
For example, Life Sciences span multiple domains ranging from pharmacy to genetics to clinical trials. In the LOD cloud prominent Life Sciences datasets are 
UniProt (protein function), Drugbank (drugs), and chEMBL (properties of molecules).
%This necessitates the runtime integration of different datasets of significant size. 
Being able to interact with these datasets as one virtual source requires technology capable of both managing Big Linked Data, as well as successfully answering complex federated queries.

%\vfill %otherwise latex stress linespacing to fill page
%These challenges are being addressed by:
%\begin{itemize}
%	\item \emph{Vertical scaling} is using an expensive high-end machine with a lot of RAM and CPU power. 
%	No additional software development is required in this case.
%	\item A \emph{Compression algorithm} such as HDT~\cite{DBLP:journals/ws/FernandezMGPA13} can easily compress RDF datasets by a factor of 10--20. This allows for much larger datasets to be handled 
%	by a single server.
%\end{itemize}
%An alternative is to opt for a distributed architecture:
%\begin{itemize}
%	\item \emph{Horizontal scaling} uses multiple - often cheap, low-end - instances in a distributed system. 
%	Most enterprise RDF stores support parallelization, but this can imply both a high availability
%	solution (data replication), or a sharded system (data partitions) that can deal with increasingly large datasets. 
%	\item \emph{Query federation}~\cite{DBLP:conf/semweb/SchwarteHHSS11}: All datasets are hosted by their providers and
%	a federated query engine redirects the relevant parts of each query to the right endpoint and finally combines all the recieved information to solve the query.
%	\item Native \emph{Big Data approaches} typically map SPARQL queries to SQL technologies available in the Hadoop stack: SparkSQL~\cite{cure2015evaluation} or Impala~\cite{DBLP:conf/semweb/SchatzlePNL14}.
%\end{itemize}
%Citaat SWAT4LS:The Life Sciences domain is interdisciplinary, which makes interlinking data sources interesting and crucial.
%The Linked Open Data Cloud contains many RDF data sources related to life sciences, but this comes with a set of challenges: 
%(i) the union of all datasets qualifies as Big Data and therefore puts a strain on the available technologies for querying and 
%(ii) these insights contain information of multiple datasets at once, 
%making the queries federated in nature.
%challenges we address: more repeatable and easier to run your own benchmarks
\subsection{Challenges}

Datasets on the Semantic Web can be queried using RDF database systems that (partially) support the SPARQL Protocol and Query Language (SPARQL). There is an abundance of RDF storage solutions each with their own strengths and weaknesses.
Choosing an RDF database and system architecture therefore requires making trade-offs: 

\begin{itemize}
	\item What features are required for the system of choice given the use case at hand, what features are optional?
	\item What hardware is required to achieve a certain performance?
	\item What are the risks when using research prototypes instead of mature vendor-backed solutions? 
\end{itemize}

To make matters even more complicated, database vendors are continuously improving their products rendering previous benchmark results quickly outdated.
The goal of this work is to provide an up-to-date view on the RDF storage solution space.
By providing scripts for deployment and post-processing of results, we provide a~feasible approach to run benchmarks with own data and queries within a limited time window.
This work also offers a methodology to make benchmarks more reproducible and therefore the results more easily generally applicable.

\subsection{Research Questions}

The work presented here is structured around 3 research questions (\textbf{RQs}):

\begin{enumerate}
%Methods hardware, configs, wrapper, hardware, amis,... query completeness diagnostics
\item \textit{How to run a query performance benchmark in a reproducible and reliable way?}
This will be mostly addressed in the section `Benchmark Approach'. Reliability is the focus of result sections `Query Result Completeness' and `Benchmark Error Analysis', 
which deal with errors and query completeness. 

%Options: Horizontal, vertical, compression, federation big data approaches, multithreading
\item \textit{What are the different options and the associated trade-offs when choosing a Linked Data infrastructure setup in the context of Big Linked Data? How can different setups be compared? }
In the section `Results~I' we will demonstrate that the choice of engine depends on the size of the dataset. In `Results~II' we will investigate which engine works best for certain query types. How completely different solutions can be compared is the subject of the section `Benchmark Cost' in `Results III'. There we also compare the results on artificial data with a real-world dataset.

%context=caching and server load, query completeness
\item \textit{What is the relative influence on the measured performance of contextual factors for the different RDF solutions? Is the impact similar for all solutions?}
In the section `Results II' we will demonstrate that query runtime results cannot be interpreted without taking into account the \emph{query context}: server load, availability, caching effects, etc. all have an impact on the individual runtimes.

%query types, real world vs Watdiv, Watdiv sizes, Decisiontree = unbiased
%\item \textit{How do the RDF systems behave in a real-world setting?}
%In section `Results~III' we run a custom Life Sciences benchmark in the %context of federated faceted browsing. 

\end{enumerate}