
%
%RESULTS Rev1: Notebook Rev1_14

%Bla_N1_64_W1000_Opt Gra_N1_64_W1000_Opt ES_N1_64_W1000_Def Vir_N1_64_W1000_Opt LDF_N1_64_W1000_Def
%template_type 					
%C 	11.351180 	33.415042 	300.000000 	30.119333 	300.000000
%F 	0.719852 	5.488321 	145.693301 	2.129451 	230.302172
%L 	1.129471 	3.571551 	40.578727 	0.288724 	181.020213
%S 	0.716312 	1.137674 	62.536523 	0.671059 	206.013166


%Bla_N1_64_W1000_Opt 	Gra_N1_64_W1000_Opt 	ES_N1_64_W1000_Def 	Vir_N1_64_W1000_Opt 	LDF_N1_64_W1000_Def
%template 					
%C1 	4.940516 	41.336715 	300.000000 	50.035636 	300.000000	Bla1
%C2 	17.761844 	25.493369 	300.000000 	10.203031 	300.000000	Vir1
%F1 	0.670688 	0.625516 	9.861268 	0.071896 	300.000000	Vir2
%F2 	0.664716 	1.836255 	138.434201 	4.051152 	266.996652	Bla2
%F3 	0.988516 	3.994012 	285.952252 	3.760456 	278.236529	Bla3
%F4 	1.205160 	20.921219 	291.791630 	2.744209 	300.000000	Bla4
%F5 	0.070181 	0.064602 	2.427156 	0.019544 	6.277677	Vir3
%L1 	0.036493 	0.008071 	1.487417 	0.006973 	2.943234	Vir4
%L2 	2.324181 	3.226320 	24.471601 	0.357609 	300.000000	Vir5
%L3 	0.038276 	0.015445 	1.084097 	0.006927 	2.157830	Vir6
%L4 	0.804170 	4.059377 	53.451901 	0.356231 	300.000000	Vir7
%L5 	2.444232 	10.548542 	122.398621 	0.715878 	300.000000	Vir8
%S1 	0.047244 	0.015712 	3.928094 	0.105687 	4.570855	Gra1
%S2 	0.984467 	2.272204 	48.099443 	0.191565 	300.000000	Vir9
%S3 	1.780878 	2.947183 	29.250842 	0.353435 	300.000000	Vir10
%S4 	0.718509 	0.535923 	80.476401 	0.085778 	300.000000	Vir11
%S5 	1.099191 	1.548881 	263.311051 	0.127885 	300.000000	Vir12
%S6 	0.341393 	0.638479 	12.351478 	3.827406 	236.382778	Bla5
%S7 	0.042499 	0.005334 	0.338355 	0.005658 	1.138527	Gra2


%\caption{Average Runtime per query template for 5 single-node setups. \textbf{TPF1\_64} has only 5 templates which do not coincide with the timeout of 300s, for \textbf{ES1\_64\_Def} this is alread 15 templates.
%\textbf{Vir1\_64\_Opt} is the fastest engine for 13 templates, \textbf{Gra1\_64\_Opt} for and \textbf{Bla1\_64\_Opt} for 3 templates each. Template \textbf{C3} was omitted due to query completeness issues. Blazegraph was the only engine to retrieve all results. } 
The queries of the WatDiv benchmarks are all BGPs but have different shapes and selectivity properties. The benchmark generator has 20 templates which can be further organized into 4 template categories (shapes). 
n Figure~\ref{fig:Fig05_WatdivTemplates} we show the average runtime per template for 5 stores on WatDiv1000M.
\begin{itemize}
	\item \textbf{Template timeouts:} For \textbf{TPF1\_64} 11 runtime averages coincide with the benchmark timeout (300s). Successful queries are spread out over the different types: \textbf{F}:3, \textbf{L}:2 and \textbf{S}:3 .
	\textbf{ES1\_64\_Def} has timeouts for the 2 \textbf{C} queries,  2 \textbf{F} queries, and 1 \textbf{S} query. The other stores have no averages close to timeout.
	\item  \textbf{Template winners:} \textbf{Vir1\_64\_Opt} is the fastest engine for 12 templates. These are divided as: \textbf{C}:1, \textbf{F}:2, \textbf{S}:4, and all 5 \textbf{L}-templates.
	\textbf{Gra1\_64\_Opt} performs best for 2 \textbf{S}-templates, \textbf{Bla1\_64\_Opt} wins on 1 \textbf{C}-,  2 \textbf{F}-  and 1 S-template.
	Template \textbf{C3} was omitted due to query completeness issues. Blazegraph was the only engine to retrieve all results within the timeout boundary.
	\item \textbf{ETL winner:} The most important for the total benchmark time is the \textbf{C1}-template which explains why Blazegraph is the fastest in the full ETL-run.
\end{itemize}

%If we generalize further and only distinguish between 4 query template types, as can be seen \todo{UPDATE} in Figure~\ref{fig:Fig06_WatdivTemplateTypes}, it becomes even more apparent where the difference between Blazegraph and Virtuoso can be situated: the \textbf{C}-templates.
%\begin{itemize}
%	\item \textbf{Ranking per template type:} The order is very stable, \textbf{Vir1\_64\_Opt} first, followed by  \\ \textbf{Bla1\_64\_Opt} and \textbf{Gra1\_64\_Opt}. Only for \textbf{C}-templates Blazegraph has the advantage  by a factor 3: 10s vs 30s. The differences on the other templates are lower by an order of magnitude, each time in the range of 0.2 - 0.5 seconds. For the \textbf{S}-templates GraphDB performs slightly better than Blazegraph.
%	\item \textbf{Engine specialties:} For Blazegraph the \textbf{C}, \textbf{F}, and \textbf{S}-templates result in similar runtimes. GraphDB has a small preference for \textbf{S}-templates. Virtuoso is much better than the competition for \textbf{L}- and \textbf{S}-queries. For the \textbf{F}-template all three engines perform similarly.
%\end{itemize}

In Figure~\ref{fig:Fig06_TemplatesVSHardware} we demonstrate the impact of different hardware and engine configuration impact the runtime of the individual query runtimes. The improvement in average query runtime is rather homogeneous across the different query categories for all stores. The results in the \emph{Optimized} setting are worse for Virtuoso as configuration was more conservative as compared to the \emph{Default} configuration.
