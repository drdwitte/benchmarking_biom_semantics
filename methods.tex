In this benchmark we would like to discover trends when modifying certain aspects of the benchmark setup. In section~\ref{subsec:bmexplore} we define a \emph{benchmark space}. For every dimension in this space we try to at least test two possible values.
Performance is not always the first concern in a system architecture. In section~\ref{subsec:featurematrix} we describe an approach using a Feature Matrix in which weights can be assigned to certain properties of a system in order to make a ranking of the different systems given a use case. Section~\ref{subsec:bmscheme} gives a detailed explanation on our attempt at making the benchmark itself more easily reproducible and comparable with other work. Section~\ref{subsec:dataqueries} introduces the benchmark data and query-sets used in this work. 

\subsection{Benchmark Space Exploration}
\label{subsec:bmexplore}
Assessing the performance of an RDF system with a given benchmark starts with the identification of the set of parameters its results depend on. 
The actual outcome is a function of (at least) the following dimensions, for which we test multiple values:

\begin{itemize}
	\item \textbf{The choice of database engine:} We assess 7 different systems, 4 \emph{Vendors} and 3 \emph{SemWeb} systems.
	\item \textbf{The server hardware---especially memory:} We distinguish between 32GB and 64GB of RAM on the server.
	\item \textbf{The size of the (optionally) distributed system:} We run tests for single and 3-node setups when supported by the RDF database. Federated systems consists of $N+1$ nodes, with N the number of slaves (1 or 3) nodes, and 1 federator node. To clarify: $N=3$ thus corresponds to 3 instances for \emph{Vendor} systems, while $N=3$ for federated setups requires $3+1$ instances. The choice for $N=3$ is related to the fact that for one of the systems only a 3-node configuration is available.
	\item \textbf{The query properties:} The WatDiv benchmark query-set contains BGP queries, while the Ontoforce dataset consists mainly of complex aggregation-based queries.
	\item \textbf{The number of dataset triples:} We run 3 datasets of WatDiv, with 10~million, 100~million, and 1~billion triples. The Ontoforce dataset contains 2.4~billion triples.
	\item \textbf{The way in which the RDF system is configured:} We used the recommended configuration in the store's documentation as the \emph{Default} configuration and sent out a request for information to the vendors to achieve an \emph{Optimized} setup for WatDiv1000M.
	\item \textbf{The state of the system when the query is launched:} We distinguish between a single-threaded warm-up run and a multi-threaded stress test (5 clients). We also investigate whether caching effects play a role in the runtime behavior.
\end{itemize} 


Testing every possible combination of parameters is very time and resource consuming and not necessarily the most informative. Therefore we opted for a greedy exploration of this space consisting of 51 2-phase  benchmarks (incl. re-runs), each with a warm-up and a consecutive stress test. Table~\ref{bmspace} gives an overview of the benchmarks we performed.

%wordt in result intros al verwerkt
%As a performance measure there are also a number of metrics to choose from. If we focus on runtime we have to distinguish between comparing the \emph{runtime of the median query} or its runtime distribution versus the \emph{total runtime} of a full query mix. The first is independent of extreme values while the latter is  heavily affected by the runtime on the slowest queries and a possible timeout parameter. 
%The median query runtime is important for interactive systems while the total runtime is important to assess a system's usability in an ETL context. To take into account different types of system architectures, hardware and differing licensing costs we opt to use \emph{benchmark cost} as a unification parameter.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[htbp!]
	\centering
	\caption{Overview of benchmarks run in this study.}
	\label{bmspace}

	\begin{tabular}{l|l|cccc}
		\hline
			
		\textbf{Systems} & \textbf{Setup} & \multicolumn{3}{l}{\textbf{WatDiv}} &   \multicolumn{1}{l}{\textbf{Onto-}} \\
		\; & \; & \textbf{10M} & \textbf{100M} & \textbf{1000M} & \textbf{force} \\

		\hline

		\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Vendors \\ (4)\end{tabular}}    & 32             & \checkmark                                & \checkmark                                 & \checkmark                                  &                                    \\
		& 64             &                                  &                                   & \checkmark                                  &                                    \\
		& 64/Opt         &                                  &                                   & \checkmark                                  & \checkmark                                  \\ \hline
		\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Multi-\\ Node (2)\end{tabular}} & 3 x 32         &                                  &                                   & \checkmark                                  &                                    \\
		& 3 x 64/Opt     &                                  &                                   &                                    & \checkmark                                  \\ \hline
		\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Semantic\\ Web  (3)\end{tabular}} & 64  &   & \checkmark  & \checkmark  & \checkmark \\
		& 3 x 64 &  & \checkmark  & \checkmark  & \checkmark    \\ \hline                             
	\end{tabular}
\end{table}

