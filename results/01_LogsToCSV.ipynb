{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%reset\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "#false positive warnings all the time:\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "import os.path\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#source: http://stackoverflow.com/questions/5917082/regular-expression-to-match-numbers-with-or-without-commas-and-decimals-in-text\n",
    "regex_number_with_commas = '(\\d+|\\d{1,3}(,\\d{3})*)(\\.\\d+)?'\n",
    "regex_decimal_number = '(\\d+\\.)?\\d+'\n",
    "\n",
    "\n",
    "def removeCommasInteger(i):\n",
    "    return int(i.replace(\",\",\"\"))\n",
    "\n",
    "#Thanks to: https://regex101.com/ for testing the regexes live!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulation identifiers and paths\n",
    "\n",
    "Simulation is identified as a **tuple**: (Store, Number of nodes, Amount of RAM, Dataset, Config, Additional info field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_tuple = (\"Fuseki\", 1, 64, \"Ontoforce\", \"Default\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "* simulation tuple -> long_identifier\n",
    "* simulation tuple -> short_identifier\n",
    "* simulation tuple -> path to log file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateSimulationID(tup):\n",
    "    identifier = tup[0] \\\n",
    "            + \"_N\" + str(tup[1]) \\\n",
    "            + \"_\" + str(tup[2]) \\\n",
    "            + \"_\" + tup[3] \\\n",
    "            + \"_\" + tup[4] \\\n",
    "    \n",
    "    extra = \"\"\n",
    "    if len(tup[5]) !=0:\n",
    "        extra = \"_\" + str(tup[5])\n",
    "    \n",
    "    return identifier+extra\n",
    "\n",
    "\n",
    "simulation_map = {\n",
    "    \"Watdiv10M\": \"W10\", \"Watdiv100M\": \"W100\", \"Watdiv1000M\": \"W1000\", \"Ontoforce\": \"Ont\"\n",
    "}\n",
    "\n",
    "def generateSimulationIDCompact(tup, pref_length=3):\n",
    "    #pref_length = 3\n",
    "    identifier = tup[0][:pref_length] \\\n",
    "            + \"_N\" + str(tup[1]) \\\n",
    "            + \"_\" + str(tup[2]) \\\n",
    "            + \"_\" + simulation_map[tup[3]] \\\n",
    "            + \"_\" + str(tup[4])[:pref_length] \\\n",
    "    \n",
    "    extra = \"\"\n",
    "    if len(tup[5]) !=0:\n",
    "        extra = \"_\" + str(tup[5])\n",
    "    \n",
    "    return identifier+extra\n",
    "\n",
    "def generateFullPathErrorLog(path, tup):\n",
    "    return path + tup[0] + '/' +  generateSimulationID(tup) + \"_output.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuseki_N1_64_Ontoforce_Default\n",
      "Fus_N1_64_Ont_Def\n",
      "./Fuseki/Fuseki_N1_64_Ontoforce_Default_output.log\n",
      "Log file found? True\n"
     ]
    }
   ],
   "source": [
    "home_path = \"./\"\n",
    "\n",
    "print(generateSimulationID(example_tuple))\n",
    "print(generateSimulationIDCompact(example_tuple))\n",
    "sim_identifier = generateSimulationIDCompact(example_tuple)\n",
    "full_path = generateFullPathErrorLog(home_path,example_tuple)\n",
    "print(full_path)\n",
    "print('Log file found? ' + str(os.path.isfile(full_path))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert log file into csv document\n",
    "\n",
    "Fields:\n",
    "\n",
    "- query_order: the index of the query\n",
    "- query_name\n",
    "- threadID\n",
    "- number of results\n",
    "- runtime\n",
    "- simulation_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Extract Query Thread IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getIDsWarmupThreads(path):\n",
    "\n",
    "    queryThreadList = []\n",
    "    querying_started = False\n",
    "\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "\n",
    "            if 'Running Warmups...' in line:\n",
    "                querying_started = True\n",
    "            \n",
    "            if 'Running Benchmarks...' in line:\n",
    "                break\n",
    "                \n",
    "            if not querying_started:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            if 'Running Operation ' in line:\n",
    "                m = re.search('Thread (\\d+)',line)\n",
    "                queryThreadList.append(m.group(1))\n",
    "\n",
    "    return list(set(queryThreadList))\n",
    "\n",
    "def getIDsQueryThreads(path):\n",
    "    queryThreadList = []\n",
    "    querying_started = False\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            \n",
    "            if 'Running Benchmarks...' in line:\n",
    "                querying_started = True\n",
    "            \n",
    "            #some of the log files are appended versions of multiple benchmark runs\n",
    "            if querying_started and 'Running Warmups...' in line:\n",
    "                break\n",
    "                \n",
    "            if not querying_started:\n",
    "                continue\n",
    "                \n",
    "            if 'Running Operation ' in line:\n",
    "                m = re.search('Thread (\\d+)',line)\n",
    "                queryThreadList.append(m.group(1))\n",
    "\n",
    "    return list(set(queryThreadList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n",
      "['537', '538', '536', '533', '535']\n"
     ]
    }
   ],
   "source": [
    "ids_warmupthreads = getIDsWarmupThreads(full_path)\n",
    "print(ids_warmupthreads)\n",
    "ids_querythreads = getIDsQueryThreads(full_path)\n",
    "print(ids_querythreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Extract logs per queryID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLogLinesOfWThread(qid, path):\n",
    "    lines = []\n",
    "    querying_started = False\n",
    "    \n",
    "    c = 0\n",
    "    c_start = 0\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            c+=1\n",
    "            \n",
    "            if 'Running Warmups...' in line:\n",
    "                c_start = c\n",
    "                querying_started = True\n",
    "            \n",
    "            \n",
    "            if 'Running Benchmarks...' in line:\n",
    "                querying_started = False\n",
    "                \n",
    "                break\n",
    "              \n",
    "            if not querying_started:\n",
    "                continue\n",
    "            \n",
    "            if ('Thread ' + str(qid) + \"]\") in line:\n",
    "                \n",
    "                if 'Running Operation' in line:\n",
    "                    if '...[Thread' in line: #loglines accidentally concatenated\n",
    "                        line1 = line[:line.find('...[Thread') +3]\n",
    "                        line2 = line[line.find('...[Thread') +3:]\n",
    "                        lines.append(line1.strip())\n",
    "                        lines.append(line2.strip())\n",
    "                        \n",
    "                        #print(line1)\n",
    "                        #print(line2)\n",
    "                    else:\n",
    "                        lines.append(line.strip())\n",
    "                elif 'result(s) in' in line:\n",
    "                    lines.append(line.strip())\n",
    "                elif 'got error' in line:\n",
    "                    lines.append(line.strip())\n",
    "                    \n",
    "    #print(\"Loglines: \" + str(c_start) + \" -> \" + str(c))\n",
    "    return lines\n",
    "\n",
    "def getLogLinesOfQThread(qid, path):\n",
    "    lines = []\n",
    "    querying_started = False\n",
    "\n",
    "    c = 0\n",
    "    c_start = 0\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            c+=1\n",
    "            \n",
    "            if 'Running Benchmarks...' in line:\n",
    "                querying_started = True\n",
    "                c_start = c\n",
    "            \n",
    "            #some of the log files are appended versions of multiple benchmark runs\n",
    "            if querying_started and 'Running Warmups...' in line:\n",
    "                break\n",
    "                \n",
    "            if not querying_started:\n",
    "                continue\n",
    "            \n",
    "            if ('Thread ' + str(qid) + \"]\") in line:\n",
    "                \n",
    "                if 'Running Operation' in line:\n",
    "                    if '...[Thread' in line: #loglines accidentally concatenated\n",
    "                        line1 = line[:line.find('...[Thread') +3]\n",
    "                        line2 = line[line.find('...[Thread') +3:]\n",
    "                        lines.append(line1.strip())\n",
    "                        lines.append(line2.strip())\n",
    "                        \n",
    "                        #print(line1)\n",
    "                        #print(line2)\n",
    "                    else:\n",
    "                        lines.append(line.strip())\n",
    "                elif 'result(s) in' in line:\n",
    "                    lines.append(line.strip())\n",
    "                elif 'got error' in line:\n",
    "                    lines.append(line.strip())\n",
    "\n",
    "    #print(\"Loglines: \" + str(c_start) + \" -> \" + str(c))\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\t2446\n",
      "537:\t575\n",
      "538:\t571\n",
      "536:\t572\n",
      "533:\t573\n",
      "535:\t571\n"
     ]
    }
   ],
   "source": [
    "for tid in ids_warmupthreads:\n",
    "    print(str(tid) + \":\\t\" + str(len(getLogLinesOfWThread(tid, full_path))))\n",
    "for tid in ids_querythreads:\n",
    "    print(str(tid) + \":\\t\" + str(len(getLogLinesOfQThread(tid, full_path))))    \n",
    "    \n",
    "lines = getLogLinesOfWThread(1, full_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Convert logs per thread into query information tuples\n",
    "\n",
    "Log lines consist of a line stating a query is executed (contains query name) and a second line stating whether the query succeeded, the number of results and the runtime. Note that these lines are with the same thread and not consecutively in the log file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTupleFromResultsLine(line, sim_id, query_name, thread_id, thread_type, order_id):\n",
    "    \n",
    "    regex_results = 'got (' + regex_number_with_commas + ') result'\n",
    "    regex_seconds = 'in ('+ regex_decimal_number + ')s$'\n",
    "    \n",
    "    m = re.search(regex_results, line)\n",
    "    number_of_results = removeCommasInteger(m.group(1))\n",
    "    m = re.search(regex_seconds, line)\n",
    "    number_of_seconds = float(m.group(1))\n",
    "    \n",
    "    return (sim_id, query_name, thread_id, thread_type, order_id, number_of_results, number_of_seconds, 'SUCCESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-16 08:02:42,803 - Logger - INFO - STATUS: [Thread 1] got 1 result(s) in 0.011952997s\n",
      "('Fus_N1_64_Ont_Def', 'query_name', 1, 'warmup', 0, 1, 0.011952997, 'SUCCESS')\n"
     ]
    }
   ],
   "source": [
    "example_line = lines[15]\n",
    "print(example_line)\n",
    "print(generateTupleFromResultsLine(example_line, generateSimulationIDCompact(example_tuple), \\\n",
    "                                  'query_name', 1, 'warmup', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateQueryEventList(full_path, tid, thread_type, queryPath, timeout, sim_id):\n",
    "    resultList = []\n",
    "    \n",
    "    lines = None\n",
    "    if thread_type == 'warmup':\n",
    "        lines = getLogLinesOfWThread(tid, full_path)\n",
    "    else :\n",
    "        lines = getLogLinesOfQThread(tid, full_path)\n",
    "    \n",
    "    readResults = False\n",
    "    query = None\n",
    "    c = 0\n",
    "    \n",
    "    for l in lines:\n",
    "        \n",
    "   \n",
    "        if readResults:\n",
    "            \n",
    "\n",
    "            if 'result(s) in ' in l:\n",
    "                \n",
    "                tup = generateTupleFromResultsLine(l, sim_id, query, tid, thread_type, c)\n",
    "                resultList.append(tup)\n",
    "                \n",
    "\n",
    "            elif 'got error' in l:\n",
    "\n",
    "                if 'Operation Callable' in l:\n",
    "\n",
    "                    tup = (sim_id, query, tid, thread_type, c, -1, timeout, 'TIMEOUT')\n",
    "                    resultList.append(tup)\n",
    "                    \n",
    "                else:\n",
    "                    #print(l)\n",
    "                    tup = (sim_id, query, tid, thread_type, c, -1, -1, 'ERROR')\n",
    "                    resultList.append(tup)                                    \n",
    "            else:\n",
    "\n",
    "                #if next line is also a 'Running Operation' then we also flag as error\n",
    "                tup = (sim_id, query, tid, thread_type, c, -1, -1, 'ERROR')\n",
    "                resultList.append(tup)                                    \n",
    "\n",
    "\n",
    "            readResults = False\n",
    "\n",
    "        if 'Running Operation' in l:\n",
    "\n",
    "            p = l.find(queryPath)\n",
    "            p_end = l.find('...')\n",
    "            \n",
    "            if p>=0: \n",
    "                readResults = True\n",
    "                query = str(l[p+len(queryPath):-3])\n",
    "                #print(query)\n",
    "                c+=1\n",
    "    \n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fus_N1_64_Ont_Def', 'queries/xhf', 1, 'warmup', 1, 0, 0.281765686, 'SUCCESS')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xzany', 1, 'warmup', 2, -1, 300, 'TIMEOUT')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xrr', 1, 'warmup', 3, -1, 300, 'TIMEOUT')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xzark', 1, 'warmup', 4, -1, 300, 'TIMEOUT')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xzape', 1, 'warmup', 5, -1, 300, 'TIMEOUT')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xzack', 1, 'warmup', 6, -1, 300, 'TIMEOUT')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xuj', 1, 'warmup', 7, 0, 0.017050155, 'SUCCESS')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xzauh', 1, 'warmup', 8, 1, 0.011952997, 'SUCCESS')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xwd', 1, 'warmup', 9, 146, 0.910000413, 'SUCCESS')\n",
      "('Fus_N1_64_Ont_Def', 'queries/xzajc', 1, 'warmup', 10, 0, 0.010266175, 'SUCCESS')\n"
     ]
    }
   ],
   "source": [
    "eventlist = generateQueryEventList(full_path, 1, 'warmup', \"templated/\", 300, sim_identifier)\n",
    "c=0\n",
    "for e in eventlist:\n",
    "   \n",
    "    print(e)\n",
    "    c+=1\n",
    "    if c==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Create dataframe with tuples of 1 thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WARNING: don't append row by row, it's very slow, internally creates a new dataframe since dataframes are immutable\n",
    "# speed went from +3 minutes -> subsecond!!\n",
    "\n",
    "def queryEventsToDataframe(queryEventList):\n",
    "    \n",
    "    infomaps = []\n",
    "    c=0\n",
    "    for tup in queryEventList:\n",
    "        \n",
    "        infomap = {}\n",
    "        infomap['sim_id'] = tup[0]\n",
    "        infomap['query_name'] = tup[1]\n",
    "        infomap['thread_id'] = int(tup[2])\n",
    "        infomap['thread_type'] = tup[3]\n",
    "        infomap['order_id'] = int(tup[4])\n",
    "        infomap['number_of_results'] = int(tup[5])\n",
    "        infomap['runtime'] = tup[6]\n",
    "        infomap['flag'] = tup[7]\n",
    "        row = pd.Series(infomap)\n",
    "        #df.loc[c] = row\n",
    "        c+=1\n",
    "        infomaps.append(row)\n",
    "        \n",
    "        #df.convert_objects(convert_numeric=True)\n",
    "        \n",
    "    df = pd.concat(infomaps, axis=1).T\n",
    "    df = df[['sim_id', 'query_name', 'thread_id', 'thread_type', 'order_id', 'number_of_results', \\\n",
    "                               'runtime', 'flag']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_id</th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>number_of_results</th>\n",
       "      <th>runtime</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xhf</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281766</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xzany</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xrr</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xzark</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xzape</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sim_id     query_name thread_id thread_type order_id  \\\n",
       "0  Fus_N1_64_Ont_Def    queries/xhf         1      warmup        1   \n",
       "1  Fus_N1_64_Ont_Def  queries/xzany         1      warmup        2   \n",
       "2  Fus_N1_64_Ont_Def    queries/xrr         1      warmup        3   \n",
       "3  Fus_N1_64_Ont_Def  queries/xzark         1      warmup        4   \n",
       "4  Fus_N1_64_Ont_Def  queries/xzape         1      warmup        5   \n",
       "\n",
       "  number_of_results   runtime     flag  \n",
       "0                 0  0.281766  SUCCESS  \n",
       "1                -1       300  TIMEOUT  \n",
       "2                -1       300  TIMEOUT  \n",
       "3                -1       300  TIMEOUT  \n",
       "4                -1       300  TIMEOUT  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = queryEventsToDataframe(eventlist)\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Merge dataframes of all threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateQueryEventDataframe(bm_tuple, home_path, query_path, timeout):\n",
    "    \n",
    "    path_logfile = generateFullPathErrorLog(home_path, bm_tuple)\n",
    "    sim_id = generateSimulationIDCompact(bm_tuple)\n",
    "    print(\"PROCESSING SIM_ID: \" + sim_id)\n",
    "    print(path_logfile)\n",
    "    \n",
    "    found = os.path.isfile(path_logfile)\n",
    "    print('Log file found? ' + str(found))\n",
    "    \n",
    "    if found is False:\n",
    "        return False\n",
    "    \n",
    "    warmup_t = getIDsWarmupThreads(path_logfile)\n",
    "    query_t = getIDsQueryThreads(path_logfile)\n",
    "\n",
    "    print(warmup_t)\n",
    "    print(query_t)\n",
    "    \n",
    "    df_tot = None\n",
    "    \n",
    "    for tid in warmup_t:\n",
    "        #loglines = getLogLinesOfThread(tid, path_logfile)\n",
    "        #print(\"WThread \"+str(tid)+\":\\t\" + str(len(loglines)) + \" loglines found\")\n",
    "        eventlist = generateQueryEventList(path_logfile, tid, 'warmup', query_path, timeout, sim_id)\n",
    "        print(\"WThread \" + str(tid) + \": \" + str(len(eventlist)) + \" query events found\")\n",
    "        \n",
    "        #TODO remove\n",
    "        print(eventlist[0])\n",
    "        \n",
    "        if df_tot is not None:\n",
    "            df = queryEventsToDataframe(eventlist)\n",
    "            df_tot = pd.concat([df_tot, df])\n",
    "        else:\n",
    "            df_tot = queryEventsToDataframe(eventlist)\n",
    "            \n",
    "    for tid in query_t:\n",
    "        #loglines = getLogLinesOfThread(tid, path_logfile)  \n",
    "        #print(\"QThread \"+str(tid)+\":\\t\" + str(len(loglines)) + \" loglines found\")\n",
    "        eventlist = generateQueryEventList(path_logfile, tid, 'stress', query_path, timeout, sim_id)\n",
    "        print(\"QThreads \" + str(tid)+ \": \" + str(len(eventlist)) + \" query events found\")\n",
    "        \n",
    "        if df_tot is not None:\n",
    "            df = queryEventsToDataframe(eventlist)\n",
    "            df_tot = pd.concat([df_tot, df])\n",
    "        else:\n",
    "            df_tot = queryEventsToDataframe(eventlist)\n",
    "            \n",
    "\n",
    "    \n",
    "    return df_tot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING SIM_ID: Fus_N1_64_Ont_Def\n",
      "./Fuseki/Fuseki_N1_64_Ontoforce_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['537', '538', '536', '533', '535']\n",
      "WThread 1: 1223 query events found\n",
      "('Fus_N1_64_Ont_Def', 'queries/xhf', '1', 'warmup', 1, 0, 0.281765686, 'SUCCESS')\n",
      "QThreads 537: 287 query events found\n",
      "QThreads 538: 285 query events found\n",
      "QThreads 536: 286 query events found\n",
      "QThreads 533: 286 query events found\n",
      "QThreads 535: 285 query events found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2652, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot = generateQueryEventDataframe(example_tuple, './', 'templated/', 300)\n",
    "df_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_id</th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>number_of_results</th>\n",
       "      <th>runtime</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xhf</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281766</td>\n",
       "      <td>SUCCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xzany</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xrr</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xzark</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fus_N1_64_Ont_Def</td>\n",
       "      <td>queries/xzape</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>TIMEOUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sim_id     query_name thread_id thread_type order_id  \\\n",
       "0  Fus_N1_64_Ont_Def    queries/xhf         1      warmup        1   \n",
       "1  Fus_N1_64_Ont_Def  queries/xzany         1      warmup        2   \n",
       "2  Fus_N1_64_Ont_Def    queries/xrr         1      warmup        3   \n",
       "3  Fus_N1_64_Ont_Def  queries/xzark         1      warmup        4   \n",
       "4  Fus_N1_64_Ont_Def  queries/xzape         1      warmup        5   \n",
       "\n",
       "  number_of_results   runtime     flag  \n",
       "0                 0  0.281766  SUCCESS  \n",
       "1                -1       300  TIMEOUT  \n",
       "2                -1       300  TIMEOUT  \n",
       "3                -1       300  TIMEOUT  \n",
       "4                -1       300  TIMEOUT  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.6 Save to CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = sim_identifier + \"_queryevents.csv\"\n",
    "df_tot.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Convert all simulation data to csv\n",
    "\n",
    "## A. Watdiv (10M, 100M, 1000M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "\n",
    "#(1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "#(1, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "#(3, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "#\n",
    "#(1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "#(1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "#(1, 64, \"Watdiv1000M\", \"Optimized\", \"\")]    \n",
    "#(3, 32, \"Watdiv1000M\", \"Optimized\", \"\")]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Blazegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:40:44.174321\n",
      "PROCESSING SIM_ID: Bla_N1_32_W10_Def\n",
      "./Blazegraph/Blazegraph_N1_32_Watdiv10M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '21', '18', '23', '24', '20']\n",
      "WThread 1: 6000 query events found\n",
      "('Bla_N1_32_W10_Def', 'L3/L3_split67.sparql', '1', 'warmup', 1, 20, 0.029128175, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 22: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 2000 query events found\n",
      "QThreads 18: 4000 query events found\n",
      "QThreads 23: 2000 query events found\n",
      "QThreads 24: 4000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:40:50.869276\n",
      "PROCESSING SIM_ID: Bla_N1_32_W100_Def\n",
      "./Blazegraph/Blazegraph_N1_32_Watdiv100M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '21', '18', '23', '24', '20']\n",
      "WThread 1: 6000 query events found\n",
      "('Bla_N1_32_W100_Def', 'C1/C1_split28.sparql', '1', 'warmup', 1, 201, 4.508388634, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 22: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 2000 query events found\n",
      "QThreads 18: 2000 query events found\n",
      "QThreads 23: 4000 query events found\n",
      "QThreads 24: 4000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:40:57.337002\n",
      "PROCESSING SIM_ID: Bla_N1_32_W1000_Def\n",
      "./Blazegraph/Blazegraph_N1_32_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['96', '98', '97']\n",
      "WThread 1: 2003 query events found\n",
      "('Bla_N1_32_W1000_Def', 'F3/F3_split71.sparql', '1', 'warmup', 1, 375, 10.498607854, 'SUCCESS')\n",
      "QThreads 96: 2000 query events found\n",
      "QThreads 98: 2000 query events found\n",
      "QThreads 97: 2000 query events found\n",
      "2018-09-19 14:40:59.252884\n",
      "PROCESSING SIM_ID: Bla_N1_64_W1000_Def\n",
      "./Blazegraph/Blazegraph_N1_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '16', '19', '18', '15']\n",
      "WThread 1: 400 query events found\n",
      "('Bla_N1_64_W1000_Def', 'L5/L5_split19.sparql', '1', 'warmup', 1, 26082, 78.623036362, 'SUCCESS')\n",
      "QThreads 17: 400 query events found\n",
      "QThreads 16: 400 query events found\n",
      "QThreads 19: 400 query events found\n",
      "QThreads 18: 400 query events found\n",
      "QThreads 15: 400 query events found\n",
      "2018-09-19 14:40:59.811115\n",
      "PROCESSING SIM_ID: Bla_N1_64_W1000_Opt\n",
      "./Blazegraph/Blazegraph_N1_64_Watdiv1000M_Optimized_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['38', '37', '35', '36', '33']\n",
      "WThread 1: 400 query events found\n",
      "('Bla_N1_64_W1000_Opt', 'F1/F1_split15.sparql', '1', 'warmup', 1, 3, 36.716864324, 'SUCCESS')\n",
      "QThreads 38: 400 query events found\n",
      "QThreads 37: 400 query events found\n",
      "QThreads 35: 400 query events found\n",
      "QThreads 36: 400 query events found\n",
      "QThreads 33: 400 query events found\n",
      "2018-09-19 14:41:00.418072\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"Blazegraph\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 64, \"Watdiv1000M\", \"Optimized\", \"\")]\n",
    "\n",
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 300)\n",
    "\n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GraphDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:41:00.433539\n",
      "PROCESSING SIM_ID: Gra_N1_32_W10_Def\n",
      "./GraphDB/GraphDB_N1_32_Watdiv10M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '21', '18', '23', '24', '20']\n",
      "WThread 1: 6000 query events found\n",
      "('Gra_N1_32_W10_Def', 'S3/S3_split31.sparql', '1', 'warmup', 1, 0, 0.039665247, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 22: 4000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 4000 query events found\n",
      "QThreads 18: 2000 query events found\n",
      "QThreads 23: 2000 query events found\n",
      "QThreads 24: 2000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:41:06.712003\n",
      "PROCESSING SIM_ID: Gra_N1_32_W100_Def\n",
      "./GraphDB/GraphDB_N1_32_Watdiv100M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '21', '23', '25', '24', '20']\n",
      "WThread 1: 6000 query events found\n",
      "('Gra_N1_32_W100_Def', 'L2/L2_split77.sparql', '1', 'warmup', 1, 78, 0.144596859, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 22: 4000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 2000 query events found\n",
      "QThreads 23: 2000 query events found\n",
      "QThreads 25: 2000 query events found\n",
      "QThreads 24: 2000 query events found\n",
      "QThreads 20: 4000 query events found\n",
      "2018-09-19 14:41:12.639764\n",
      "PROCESSING SIM_ID: Gra_N1_32_W1000_Def\n",
      "./GraphDB/GraphDB_N1_32_Watdiv1000M_Default_output.log\n",
      "Log file found? False\n",
      "2018-09-19 14:41:12.641061\n",
      "PROCESSING SIM_ID: Gra_N1_64_W1000_Def\n",
      "./GraphDB/GraphDB_N1_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['34', '37', '35', '36', '33']\n",
      "WThread 1: 400 query events found\n",
      "('Gra_N1_64_W1000_Def', 'C1/C1_split6.sparql', '1', 'warmup', 1, 1424, 32.563320913, 'SUCCESS')\n",
      "QThreads 34: 400 query events found\n",
      "QThreads 37: 400 query events found\n",
      "QThreads 35: 400 query events found\n",
      "QThreads 36: 400 query events found\n",
      "QThreads 33: 400 query events found\n",
      "2018-09-19 14:41:13.199891\n",
      "PROCESSING SIM_ID: Gra_N1_64_W1000_Opt\n",
      "./GraphDB/GraphDB_N1_64_Watdiv1000M_Optimized_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['32', '34', '35', '36', '33']\n",
      "WThread 1: 400 query events found\n",
      "('Gra_N1_64_W1000_Opt', 'S4/S4_split8.sparql', '1', 'warmup', 1, 10, 1.065069501, 'SUCCESS')\n",
      "QThreads 32: 400 query events found\n",
      "QThreads 34: 400 query events found\n",
      "QThreads 35: 400 query events found\n",
      "QThreads 36: 400 query events found\n",
      "QThreads 33: 400 query events found\n",
      "2018-09-19 14:41:13.729479\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"GraphDB\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 64, \"Watdiv1000M\", \"Optimized\", \"\")]\n",
    "\n",
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 300)\n",
    "    \n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:41:13.750162\n",
      "PROCESSING SIM_ID: ES_N1_32_W10_Def\n",
      "./ES/ES_N1_32_Watdiv10M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '21', '23', '25', '24', '20']\n",
      "WThread 1: 6000 query events found\n",
      "('ES_N1_32_W10_Def', 'S6/S6_split75.sparql', '1', 'warmup', 1, 3, 0.074037429, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 22: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 4000 query events found\n",
      "QThreads 23: 2000 query events found\n",
      "QThreads 25: 4000 query events found\n",
      "QThreads 24: 2000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:41:19.781496\n",
      "PROCESSING SIM_ID: ES_N1_32_W100_Def\n",
      "./ES/ES_N1_32_Watdiv100M_Default_output.log\n",
      "Log file found? False\n",
      "2018-09-19 14:41:19.782653\n",
      "PROCESSING SIM_ID: ES_N1_32_W1000_Def\n",
      "./ES/ES_N1_32_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['1', '16']\n",
      "WThread 1: 5674 query events found\n",
      "('ES_N1_32_W1000_Def', 'S4/S4_split98.sparql', '1', 'warmup', 1, 3062, 68.098128339, 'SUCCESS')\n",
      "QThreads 1: 80 query events found\n",
      "QThreads 16: 82 query events found\n",
      "2018-09-19 14:41:21.051026\n",
      "PROCESSING SIM_ID: ES_N3_32_W1000_Def\n",
      "./ES/ES_N3_32_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '16', '18', '15', '14']\n",
      "WThread 1: 2000 query events found\n",
      "('ES_N3_32_W1000_Def', 'S5/S5_split95.sparql', '1', 'warmup', 1, -1, -1, 'ERROR')\n",
      "QThreads 17: 1320 query events found\n",
      "QThreads 16: 1348 query events found\n",
      "QThreads 18: 1346 query events found\n",
      "QThreads 15: 1331 query events found\n",
      "QThreads 14: 1343 query events found\n",
      "2018-09-19 14:41:22.931953\n",
      "PROCESSING SIM_ID: ES_N1_64_W1000_Def\n",
      "./ES/ES_N1_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['57', '53', '55', '56', '54']\n",
      "WThread 1: 400 query events found\n",
      "('ES_N1_64_W1000_Def', 'F5/F5_split0.sparql', '1', 'warmup', 1, 37, 1.90878398, 'SUCCESS')\n",
      "QThreads 57: 400 query events found\n",
      "QThreads 53: 400 query events found\n",
      "QThreads 55: 400 query events found\n",
      "QThreads 56: 400 query events found\n",
      "QThreads 54: 400 query events found\n",
      "2018-09-19 14:41:23.502947\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"ES\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 3, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 1, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    "\n",
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 300)\n",
    "    \n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Virtuoso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:41:23.524747\n",
      "PROCESSING SIM_ID: Vir_N1_32_W10_Def\n",
      "./Virtuoso/Virtuoso_N1_32_Watdiv10M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '18', '21', '25', '33', '24', '20']\n",
      "WThread 1: 6000 query events found\n",
      "('Vir_N1_32_W10_Def', 'S5/S5_split59.sparql', '1', 'warmup', 1, 0, 0.009704654, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 22: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 18: 2000 query events found\n",
      "QThreads 21: 2000 query events found\n",
      "QThreads 25: 4000 query events found\n",
      "QThreads 33: 2000 query events found\n",
      "QThreads 24: 2000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:41:29.558572\n",
      "PROCESSING SIM_ID: Vir_N1_32_W100_Def\n",
      "./Virtuoso/Virtuoso_N1_32_Watdiv100M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '21', '18', '23', '24', '20']\n",
      "WThread 1: 6000 query events found\n",
      "('Vir_N1_32_W100_Def', 'F3/F3_split99.sparql', '1', 'warmup', 1, 7, 0.018153995, 'SUCCESS')\n",
      "QThreads 17: 4000 query events found\n",
      "QThreads 22: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 2000 query events found\n",
      "QThreads 18: 4000 query events found\n",
      "QThreads 23: 2000 query events found\n",
      "QThreads 24: 2000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:41:35.229493\n",
      "PROCESSING SIM_ID: Vir_N1_32_W1000_Def\n",
      "./Virtuoso/Virtuoso_N1_32_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '13', '19', '21', '20']\n",
      "WThread 1: 2000 query events found\n",
      "('Vir_N1_32_W1000_Def', 'L3/L3_split42.sparql', '1', 'warmup', 1, 46, 1.183432207, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 13: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 2000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:41:37.838472\n",
      "PROCESSING SIM_ID: Vir_N1_32_W1000_Def_RERUN\n",
      "./Virtuoso/Virtuoso_N1_32_Watdiv1000M_Default_RERUN_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '13', '19', '14', '20']\n",
      "WThread 1: 2000 query events found\n",
      "('Vir_N1_32_W1000_Def_RERUN', 'S5/S5_split71.sparql', '1', 'warmup', 1, 0, 0.758813815, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 13: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 14: 2000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:41:40.479746\n",
      "PROCESSING SIM_ID: Vir_N3_32_W1000_Def\n",
      "./Virtuoso/Virtuoso_N3_32_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '22', '19', '21', '20']\n",
      "WThread 1: 2000 query events found\n",
      "('Vir_N3_32_W1000_Def', 'S7/S7_split66.sparql', '1', 'warmup', 1, 0, 4.633168346000001, 'SUCCESS')\n",
      "QThreads 17: 2000 query events found\n",
      "QThreads 22: 2000 query events found\n",
      "QThreads 19: 2000 query events found\n",
      "QThreads 21: 2000 query events found\n",
      "QThreads 20: 2000 query events found\n",
      "2018-09-19 14:41:43.077836\n",
      "PROCESSING SIM_ID: Vir_N1_64_W1000_Def\n",
      "./Virtuoso/Virtuoso_N1_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '16', '18', '15', '14']\n",
      "WThread 1: 400 query events found\n",
      "('Vir_N1_64_W1000_Def', 'S2/S2_split0.sparql', '1', 'warmup', 1, 1909, 1.08801167, 'SUCCESS')\n",
      "QThreads 17: 400 query events found\n",
      "QThreads 16: 400 query events found\n",
      "QThreads 18: 400 query events found\n",
      "QThreads 15: 400 query events found\n",
      "QThreads 14: 400 query events found\n",
      "2018-09-19 14:41:43.726861\n",
      "PROCESSING SIM_ID: Vir_N1_64_W1000_Opt\n",
      "./Virtuoso/Virtuoso_N1_64_Watdiv1000M_Optimized_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '16', '18', '15', '14']\n",
      "WThread 1: 400 query events found\n",
      "('Vir_N1_64_W1000_Opt', 'S5/S5_split14.sparql', '1', 'warmup', 1, 0, 0.873329978, 'SUCCESS')\n",
      "QThreads 17: 400 query events found\n",
      "QThreads 16: 400 query events found\n",
      "QThreads 18: 400 query events found\n",
      "QThreads 15: 400 query events found\n",
      "QThreads 14: 400 query events found\n",
      "2018-09-19 14:41:44.370202\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"Virtuoso\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Watdiv1000M\", \"Default\", \"RERUN\"), \\\n",
    "(\"Virtuoso\", 3, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Watdiv1000M\", \"Optimized\", \"\")]\n",
    "\n",
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 300)\n",
    "    \n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fuseki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:41:44.386388\n",
      "PROCESSING SIM_ID: Fus_N1_64_W100_Def\n",
      "./Fuseki/Fuseki_N1_64_Watdiv100M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['101', '104', '107', '105', '103']\n",
      "WThread 1: 400 query events found\n",
      "('Fus_N1_64_W100_Def', 'L5/L5_split1.sparql', '1', 'warmup', 1, 2681, 10.564796776, 'SUCCESS')\n",
      "QThreads 101: 400 query events found\n",
      "QThreads 104: 400 query events found\n",
      "QThreads 107: 400 query events found\n",
      "QThreads 105: 400 query events found\n",
      "QThreads 103: 400 query events found\n",
      "2018-09-19 14:41:45.393536\n",
      "PROCESSING SIM_ID: Fus_N1_64_W1000_Def\n",
      "./Fuseki/Fuseki_N1_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['57', '53', '55', '52', '54']\n",
      "WThread 1: 400 query events found\n",
      "('Fus_N1_64_W1000_Def', 'C3/C3_split13.sparql', '1', 'warmup', 1, -1, 300, 'TIMEOUT')\n",
      "QThreads 57: 400 query events found\n",
      "QThreads 53: 400 query events found\n",
      "QThreads 55: 400 query events found\n",
      "QThreads 52: 400 query events found\n",
      "QThreads 54: 400 query events found\n",
      "2018-09-19 14:41:45.910408\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"Fuseki\", 1, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"Fuseki\", 1, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    "\n",
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 300)\n",
    "    \n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. LDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:41:45.928030\n",
      "PROCESSING SIM_ID: LDF_N1_64_W100_Def\n",
      "./LDF/LDF_N1_64_Watdiv100M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['70', '75', '73', '76', '72']\n",
      "WThread 1: 400 query events found\n",
      "('LDF_N1_64_W100_Def', 'F4/F4_split5.sparql', '1', 'warmup', 1, 103, 12.653614641, 'SUCCESS')\n",
      "QThreads 70: 400 query events found\n",
      "QThreads 75: 400 query events found\n",
      "QThreads 73: 400 query events found\n",
      "QThreads 76: 400 query events found\n",
      "QThreads 72: 400 query events found\n",
      "2018-09-19 14:41:46.474412\n",
      "PROCESSING SIM_ID: LDF_N3_64_W100_Def\n",
      "./LDF/LDF_N3_64_Watdiv100M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['117', '116', '114', '115', '112']\n",
      "WThread 1: 400 query events found\n",
      "('LDF_N3_64_W100_Def', 'C2/C2_split7.sparql', '1', 'warmup', 1, -1, 300, 'TIMEOUT')\n",
      "QThreads 117: 400 query events found\n",
      "QThreads 116: 400 query events found\n",
      "QThreads 114: 400 query events found\n",
      "QThreads 115: 400 query events found\n",
      "QThreads 112: 400 query events found\n",
      "2018-09-19 14:41:46.980331\n",
      "PROCESSING SIM_ID: LDF_N1_64_W1000_Def\n",
      "./LDF/LDF_N1_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['308', '309', '312', '313', '314']\n",
      "WThread 1: 400 query events found\n",
      "('LDF_N1_64_W1000_Def', 'L4/L4_split7.sparql', '1', 'warmup', 1, -1, 300, 'TIMEOUT')\n",
      "QThreads 308: 400 query events found\n",
      "QThreads 309: 400 query events found\n",
      "QThreads 312: 400 query events found\n",
      "QThreads 313: 400 query events found\n",
      "QThreads 314: 400 query events found\n",
      "2018-09-19 14:41:47.566335\n",
      "PROCESSING SIM_ID: LDF_N3_64_W1000_Def\n",
      "./LDF/LDF_N3_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['311', '308', '312', '313', '310']\n",
      "WThread 1: 400 query events found\n",
      "('LDF_N3_64_W1000_Def', 'S6/S6_split3.sparql', '1', 'warmup', 1, 36, 31.203856742, 'SUCCESS')\n",
      "QThreads 311: 400 query events found\n",
      "QThreads 308: 400 query events found\n",
      "QThreads 312: 400 query events found\n",
      "QThreads 313: 400 query events found\n",
      "QThreads 310: 400 query events found\n",
      "2018-09-19 14:41:48.134878\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"LDF\", 1, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"LDF\", 3, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"LDF\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"LDF\", 3, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    "\n",
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 300)\n",
    "    \n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. FluidOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:41:48.147568\n",
      "PROCESSING SIM_ID: Flu_N3_64_W100_Def\n",
      "./FluidOps/FluidOps_N3_64_Watdiv100M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "[]\n",
      "WThread 1: 291 query events found\n",
      "('Flu_N3_64_W100_Def', 'F1/F1_split11.sparql', '1', 'warmup', 1, 2, 8.646807594, 'SUCCESS')\n",
      "2018-09-19 14:41:48.209543\n",
      "PROCESSING SIM_ID: Flu_N1_64_W1000_Def\n",
      "./FluidOps/FluidOps_N1_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['32', '37', '31', '35', '36']\n",
      "WThread 1: 400 query events found\n",
      "('Flu_N1_64_W1000_Def', 'L5/L5_split2.sparql', '1', 'warmup', 1, 13001, 1.294186533, 'SUCCESS')\n",
      "QThreads 32: 400 query events found\n",
      "QThreads 37: 400 query events found\n",
      "QThreads 31: 400 query events found\n",
      "QThreads 35: 400 query events found\n",
      "QThreads 36: 400 query events found\n",
      "2018-09-19 14:41:48.819055\n",
      "PROCESSING SIM_ID: Flu_N3_64_W1000_Def\n",
      "./FluidOps/FluidOps_N3_64_Watdiv1000M_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['426', '429', '434', '427', '428']\n",
      "WThread 1: 400 query events found\n",
      "('Flu_N3_64_W1000_Def', 'L4/L4_split4.sparql', '1', 'warmup', 1, 5952, 37.702362819, 'SUCCESS')\n",
      "QThreads 426: 400 query events found\n",
      "QThreads 429: 400 query events found\n",
      "QThreads 434: 400 query events found\n",
      "QThreads 427: 400 query events found\n",
      "QThreads 428: 400 query events found\n",
      "2018-09-19 14:41:49.432972\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"FluidOps\", 3, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"FluidOps\", 3, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    " \n",
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 300)\n",
    "    \n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## B. Ontoforce Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm_tuples = [ (\"Blazegraph\", 1, 64, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"GraphDB\", 1, 64, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"ES\", 1, 64, \"Ontoforce\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Ontoforce\", \"Optimized\", \"VWall\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Ontoforce\", \"Optimized\", \"VWall\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"0\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"1\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"2\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"AWS1\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"AWS2\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"AWS3\"), \\\n",
    "(\"Fuseki\", 1, 64, \"Ontoforce\", \"Default\", \"\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Ontoforce\", \"Default\", \"1\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Ontoforce\", \"Default\", \"2\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Ontoforce\", \"Default\", \"3\"), \\\n",
    "(\"FluidOps\", 3, 64, \"Ontoforce\", \"Default\", \"1\"), \\\n",
    "(\"FluidOps\", 3, 64, \"Ontoforce\", \"Default\", \"2\"), \\\n",
    "(\"FluidOps\", 3, 64, \"Ontoforce\", \"Default\", \"3\")]\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-19 14:41:49.450157\n",
      "PROCESSING SIM_ID: Bla_N1_64_Ont_Opt\n",
      "./Blazegraph/Blazegraph_N1_64_Ontoforce_Optimized_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "[]\n",
      "WThread 1: 468 query events found\n",
      "('Bla_N1_64_Ont_Opt', 'queries/xzaub', '1', 'warmup', 1, 0, 0.164709896, 'SUCCESS')\n",
      "2018-09-19 14:41:49.596548\n",
      "PROCESSING SIM_ID: Gra_N1_64_Ont_Opt\n",
      "./GraphDB/GraphDB_N1_64_Ontoforce_Optimized_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['245', '243', '246', '244', '247']\n",
      "WThread 1: 1223 query events found\n",
      "('Gra_N1_64_Ont_Opt', 'queries/xzalt', '1', 'warmup', 1, 0, 0.030136252, 'SUCCESS')\n",
      "QThreads 245: 542 query events found\n",
      "QThreads 243: 538 query events found\n",
      "QThreads 246: 536 query events found\n",
      "QThreads 244: 554 query events found\n",
      "QThreads 247: 562 query events found\n",
      "2018-09-19 14:41:50.537391\n",
      "PROCESSING SIM_ID: ES_N1_64_Ont_Def\n",
      "./ES/ES_N1_64_Ontoforce_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['53', '51', '52', '49', '50']\n",
      "WThread 1: 1223 query events found\n",
      "('ES_N1_64_Ont_Def', 'queries/xzasi', '1', 'warmup', 1, 1, 4.327735604000001, 'SUCCESS')\n",
      "QThreads 53: 1223 query events found\n",
      "QThreads 51: 1223 query events found\n",
      "QThreads 52: 1223 query events found\n",
      "QThreads 49: 1223 query events found\n",
      "QThreads 50: 1223 query events found\n",
      "2018-09-19 14:41:52.233641\n",
      "PROCESSING SIM_ID: Vir_N1_64_Ont_Opt\n",
      "./Virtuoso/Virtuoso_N1_64_Ontoforce_Optimized_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['26', '18', '23', '25', '27']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N1_64_Ont_Opt', 'queries/xzatg', '1', 'warmup', 1, 1, 0.03558215, 'SUCCESS')\n",
      "QThreads 26: 1223 query events found\n",
      "QThreads 18: 1223 query events found\n",
      "QThreads 23: 1223 query events found\n",
      "QThreads 25: 1223 query events found\n",
      "QThreads 27: 1223 query events found\n",
      "2018-09-19 14:41:53.984173\n",
      "PROCESSING SIM_ID: Vir_N1_64_Ont_Opt_VWall\n",
      "./Virtuoso/Virtuoso_N1_64_Ontoforce_Optimized_VWall_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['41', '38', '37', '40', '39']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N1_64_Ont_Opt_VWall', 'queries/xkq', '1', 'warmup', 1, 1, 11.361988971, 'SUCCESS')\n",
      "QThreads 41: 1223 query events found\n",
      "QThreads 38: 1223 query events found\n",
      "QThreads 37: 1223 query events found\n",
      "QThreads 40: 1223 query events found\n",
      "QThreads 39: 1223 query events found\n",
      "2018-09-19 14:41:56.028036\n",
      "PROCESSING SIM_ID: Vir_N1_32_Ont_Opt\n",
      "./Virtuoso/Virtuoso_N1_32_Ontoforce_Optimized_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '13', '19', '18', '20']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N1_32_Ont_Opt', 'queries/xzadq', '1', 'warmup', 1, 0, 0.008964334, 'SUCCESS')\n",
      "QThreads 17: 1223 query events found\n",
      "QThreads 13: 1223 query events found\n",
      "QThreads 19: 1223 query events found\n",
      "QThreads 18: 1223 query events found\n",
      "QThreads 20: 1223 query events found\n",
      "2018-09-19 14:41:57.786276\n",
      "PROCESSING SIM_ID: Vir_N1_32_Ont_Opt_VWall\n",
      "./Virtuoso/Virtuoso_N1_32_Ontoforce_Optimized_VWall_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['41', '44', '40', '43', '42']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N1_32_Ont_Opt_VWall', 'queries/xxw', '1', 'warmup', 1, 0, 1.499702434, 'SUCCESS')\n",
      "QThreads 41: 1223 query events found\n",
      "QThreads 44: 1223 query events found\n",
      "QThreads 40: 1223 query events found\n",
      "QThreads 43: 1223 query events found\n",
      "QThreads 42: 1223 query events found\n",
      "2018-09-19 14:41:59.602341\n",
      "PROCESSING SIM_ID: Vir_N3_64_Ont_Opt_0\n",
      "./Virtuoso/Virtuoso_N3_64_Ontoforce_Optimized_0_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['22', '26', '23', '25', '24']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N3_64_Ont_Opt_0', 'queries/xio', '1', 'warmup', 1, 1, 3.0818957719999998, 'SUCCESS')\n",
      "QThreads 22: 1223 query events found\n",
      "QThreads 26: 1223 query events found\n",
      "QThreads 23: 1223 query events found\n",
      "QThreads 25: 1223 query events found\n",
      "QThreads 24: 1223 query events found\n",
      "2018-09-19 14:42:01.432059\n",
      "PROCESSING SIM_ID: Vir_N3_64_Ont_Opt_1\n",
      "./Virtuoso/Virtuoso_N3_64_Ontoforce_Optimized_1_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['22', '18', '23', '25', '24']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N3_64_Ont_Opt_1', 'queries/xmq', '1', 'warmup', 1, -1, 1200, 'TIMEOUT')\n",
      "QThreads 22: 1223 query events found\n",
      "QThreads 18: 1223 query events found\n",
      "QThreads 23: 1223 query events found\n",
      "QThreads 25: 1223 query events found\n",
      "QThreads 24: 1223 query events found\n",
      "2018-09-19 14:42:03.076918\n",
      "PROCESSING SIM_ID: Vir_N3_64_Ont_Opt_2\n",
      "./Virtuoso/Virtuoso_N3_64_Ontoforce_Optimized_2_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['17', '19', '21', '18', '20']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N3_64_Ont_Opt_2', 'queries/xzamx', '1', 'warmup', 1, 0, 0.058251749, 'SUCCESS')\n",
      "QThreads 17: 1223 query events found\n",
      "QThreads 19: 1223 query events found\n",
      "QThreads 21: 1223 query events found\n",
      "QThreads 18: 1223 query events found\n",
      "QThreads 20: 1223 query events found\n",
      "2018-09-19 14:42:04.747130\n",
      "PROCESSING SIM_ID: Vir_N3_64_Ont_Opt_AWS1\n",
      "./Virtuoso/Virtuoso_N3_64_Ontoforce_Optimized_AWS1_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['41', '37', '40', '39', '42']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N3_64_Ont_Opt_AWS1', 'queries/xzach', '1', 'warmup', 1, 1, 2.3411298900000004, 'SUCCESS')\n",
      "QThreads 41: 1223 query events found\n",
      "QThreads 37: 1223 query events found\n",
      "QThreads 40: 1223 query events found\n",
      "QThreads 39: 1223 query events found\n",
      "QThreads 42: 1223 query events found\n",
      "2018-09-19 14:42:06.416818\n",
      "PROCESSING SIM_ID: Vir_N3_64_Ont_Opt_AWS2\n",
      "./Virtuoso/Virtuoso_N3_64_Ontoforce_Optimized_AWS2_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['45', '44', '40', '43', '42']\n",
      "WThread 1: 1223 query events found\n",
      "('Vir_N3_64_Ont_Opt_AWS2', 'queries/xuc', '1', 'warmup', 1, 1, 0.176659833, 'SUCCESS')\n",
      "QThreads 45: 1223 query events found\n",
      "QThreads 44: 1223 query events found\n",
      "QThreads 40: 1223 query events found\n",
      "QThreads 43: 1223 query events found\n",
      "QThreads 42: 1223 query events found\n",
      "2018-09-19 14:42:08.203842\n",
      "PROCESSING SIM_ID: Vir_N3_64_Ont_Opt_AWS3\n",
      "./Virtuoso/Virtuoso_N3_64_Ontoforce_Optimized_AWS3_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "[]\n",
      "WThread 1: 687 query events found\n",
      "('Vir_N3_64_Ont_Opt_AWS3', 'queries/xnb', '1', 'warmup', 1, -1, 1200, 'TIMEOUT')\n",
      "2018-09-19 14:42:08.397793\n",
      "PROCESSING SIM_ID: Fus_N1_64_Ont_Def\n",
      "./Fuseki/Fuseki_N1_64_Ontoforce_Default_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['537', '538', '536', '533', '535']\n",
      "WThread 1: 1223 query events found\n",
      "('Fus_N1_64_Ont_Def', 'queries/xhf', '1', 'warmup', 1, 0, 0.281765686, 'SUCCESS')\n",
      "QThreads 537: 287 query events found\n",
      "QThreads 538: 285 query events found\n",
      "QThreads 536: 286 query events found\n",
      "QThreads 533: 286 query events found\n",
      "QThreads 535: 285 query events found\n",
      "2018-09-19 14:42:09.009404\n",
      "PROCESSING SIM_ID: Flu_N1_64_Ont_Def_1\n",
      "./FluidOps/FluidOps_N1_64_Ontoforce_Default_1_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['38', '37', '39', '35', '36']\n",
      "WThread 1: 1223 query events found\n",
      "('Flu_N1_64_Ont_Def_1', 'queries/xzacq', '1', 'warmup', 1, 1, 2.670833989, 'SUCCESS')\n",
      "QThreads 38: 275 query events found\n",
      "QThreads 37: 270 query events found\n",
      "QThreads 39: 277 query events found\n",
      "QThreads 35: 290 query events found\n",
      "QThreads 36: 292 query events found\n",
      "2018-09-19 14:42:09.646465\n",
      "PROCESSING SIM_ID: Flu_N1_64_Ont_Def_2\n",
      "./FluidOps/FluidOps_N1_64_Ontoforce_Default_2_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "[]\n",
      "WThread 1: 181 query events found\n",
      "('Flu_N1_64_Ont_Def_2', 'queries/xtf', '1', 'warmup', 1, 1, 0.027565891000000002, 'SUCCESS')\n",
      "2018-09-19 14:42:09.727305\n",
      "PROCESSING SIM_ID: Flu_N1_64_Ont_Def_3\n",
      "./FluidOps/FluidOps_N1_64_Ontoforce_Default_3_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "['38', '37', '40', '35', '36']\n",
      "WThread 1: 1223 query events found\n",
      "('Flu_N1_64_Ont_Def_3', 'queries/xnh', '1', 'warmup', 1, 0, 0.009217805, 'SUCCESS')\n",
      "QThreads 38: 1223 query events found\n",
      "QThreads 37: 1223 query events found\n",
      "QThreads 40: 1223 query events found\n",
      "QThreads 35: 1223 query events found\n",
      "QThreads 36: 1223 query events found\n",
      "2018-09-19 14:42:11.344576\n",
      "PROCESSING SIM_ID: Flu_N3_64_Ont_Def_1\n",
      "./FluidOps/FluidOps_N3_64_Ontoforce_Default_1_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "[]\n",
      "WThread 1: 51 query events found\n",
      "('Flu_N3_64_Ont_Def_1', 'queries/xpx', '1', 'warmup', 1, 1, 0.016974588000000002, 'SUCCESS')\n",
      "2018-09-19 14:42:11.396588\n",
      "PROCESSING SIM_ID: Flu_N3_64_Ont_Def_2\n",
      "./FluidOps/FluidOps_N3_64_Ontoforce_Default_2_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "[]\n",
      "WThread 1: 129 query events found\n",
      "('Flu_N3_64_Ont_Def_2', 'queries/xdx', '1', 'warmup', 1, 1, 0.039536706000000005, 'SUCCESS')\n",
      "2018-09-19 14:42:11.468973\n",
      "PROCESSING SIM_ID: Flu_N3_64_Ont_Def_3\n",
      "./FluidOps/FluidOps_N3_64_Ontoforce_Default_3_output.log\n",
      "Log file found? True\n",
      "['1']\n",
      "[]\n",
      "WThread 1: 132 query events found\n",
      "('Flu_N3_64_Ont_Def_3', 'queries/xzaom', '1', 'warmup', 1, -1, 1200, 'TIMEOUT')\n",
      "2018-09-19 14:42:11.537736\n"
     ]
    }
   ],
   "source": [
    "for bm_tuple in bm_tuples:\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    \n",
    "    df = generateQueryEventDataframe(bm_tuple, './', 'templated/', 1200)\n",
    "    \n",
    "    if df is not False:\n",
    "        filename = generateSimulationID(bm_tuple)+ \"_queryevents.csv\"\n",
    "        df.to_csv('./csv/'+filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "print(str(datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
