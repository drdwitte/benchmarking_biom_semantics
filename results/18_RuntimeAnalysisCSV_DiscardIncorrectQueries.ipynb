{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "#false positive warnings all the time:\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "import os.path\n",
    "\n",
    "import time\n",
    "def print_elapsed(start):\n",
    "    t = time.time() - start\n",
    "    print(str(t) + \" secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime Analysis\n",
    "\n",
    "## Methods:\n",
    "\n",
    "* Assumption: queries are correct! This assumption will be invalidated for a number of simulations later on!\n",
    "\n",
    "### A1. Define Tquery?\n",
    "\n",
    "* Constraint: only look for query runtimes during the time the server was up (=benchmark survival). There are cases where the server crashed and the benchmarker reported timeouts.\n",
    "\n",
    "* Distinguish between time in the warmup phase (single threaded) and the stress test (multithreaded)\n",
    "\n",
    "* Per query report the number successful runs, the number of error runs and the number of timeouts\n",
    "\n",
    "* For the median runtime take timeouts and successful runtimes into account\n",
    "\n",
    "* **NEW** Remove incorrect queries before \n",
    "\n",
    "* **NEW** Remove C3 templates (pd.merge will handle this as C3s won't be in the index for Virtuoso\n",
    "\n",
    "* If query is never seen during benchmark survival we cannot say anything => it's not in our data and plots!\n",
    "\n",
    "\n",
    "### A2. Tquery dataframe:\n",
    "\n",
    "**PREFILTER ON BENCHMARK SURVIVAL**\n",
    "\n",
    "** IF LOG FILE NOT AVAILABLE:** use median reported in results csv file with thread_type=stress, successes=all, errors=0, timeouts=0\n",
    "\n",
    "**COLUMNS:**\n",
    "\n",
    "- thread_type: warmup/stress\n",
    "- successes: number of times flag == SUCCESS\n",
    "- errors: number of times flag == ERROR\n",
    "- timeouts: number of times flag == TIMEOUT\n",
    "- incorrect: number of times correct = INCORRECT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Query Runtime dataframe from events file: Tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateFilenameQueryEventsCorrect(bmtuple):\n",
    "    fname = './csv_correct/' +  bmtuple[0] + \"_N\" + str(bmtuple[1]) + \"_\" + str(bmtuple[2]) + \"_\" + bmtuple[3] + \"_\" + bmtuple[4]\n",
    "    if len(str(bmtuple[5])) != 0:\n",
    "        fname = fname + \"_\" + str(bmtuple[5])\n",
    "    return fname + \"_queryevents_correct.csv\"\n",
    "\n",
    "def generateFilenameRuntimesCorrect(bmtuple):\n",
    "    fname = './runtime_csv_correct/' +  bmtuple[0] + \"_N\" + str(bmtuple[1]) + \"_\" + str(bmtuple[2]) + \"_\" + bmtuple[3] + \"_\" + bmtuple[4]\n",
    "    if len(str(bmtuple[5])) != 0:\n",
    "        fname = fname + \"_\" + str(bmtuple[5])\n",
    "    return fname + \"_queryruntimes_correct.csv\"\n",
    "\n",
    "def generate_sorted_events_filename(tup):\n",
    "    return 'query_events_sorted/'+generateSimulationID(tup)+\"_events_sorted.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/Virtuoso_N1_32_Watdiv1000M_Default_queryevents_correct.csv\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_id</th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>number_of_results</th>\n",
       "      <th>runtime</th>\n",
       "      <th>flag</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vir_N1_32_W1000_Def</td>\n",
       "      <td>L3/L3_split42.sparql</td>\n",
       "      <td>1</td>\n",
       "      <td>warmup</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1.183432</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vir_N1_32_W1000_Def</td>\n",
       "      <td>L3/L3_split42.sparql</td>\n",
       "      <td>17</td>\n",
       "      <td>stress</td>\n",
       "      <td>1505</td>\n",
       "      <td>46</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vir_N1_32_W1000_Def</td>\n",
       "      <td>L3/L3_split42.sparql</td>\n",
       "      <td>13</td>\n",
       "      <td>stress</td>\n",
       "      <td>1040</td>\n",
       "      <td>46</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vir_N1_32_W1000_Def</td>\n",
       "      <td>L3/L3_split42.sparql</td>\n",
       "      <td>19</td>\n",
       "      <td>stress</td>\n",
       "      <td>1896</td>\n",
       "      <td>46</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vir_N1_32_W1000_Def</td>\n",
       "      <td>L3/L3_split42.sparql</td>\n",
       "      <td>21</td>\n",
       "      <td>stress</td>\n",
       "      <td>1610</td>\n",
       "      <td>46</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>CORRECT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sim_id            query_name  thread_id thread_type  order_id  \\\n",
       "0  Vir_N1_32_W1000_Def  L3/L3_split42.sparql          1      warmup         1   \n",
       "1  Vir_N1_32_W1000_Def  L3/L3_split42.sparql         17      stress      1505   \n",
       "2  Vir_N1_32_W1000_Def  L3/L3_split42.sparql         13      stress      1040   \n",
       "3  Vir_N1_32_W1000_Def  L3/L3_split42.sparql         19      stress      1896   \n",
       "4  Vir_N1_32_W1000_Def  L3/L3_split42.sparql         21      stress      1610   \n",
       "\n",
       "   number_of_results   runtime     flag  correct  \n",
       "0                 46  1.183432  SUCCESS  CORRECT  \n",
       "1                 46  0.014287  SUCCESS  CORRECT  \n",
       "2                 46  0.009484  SUCCESS  CORRECT  \n",
       "3                 46  0.008077  SUCCESS  CORRECT  \n",
       "4                 46  0.007975  SUCCESS  CORRECT  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_file = generateFilenameQueryEventsCorrect(('Virtuoso',1,32,'Watdiv1000M', 'Default',''))\n",
    "print(events_file)\n",
    "print(os.path.isfile(events_file))\n",
    "\n",
    "df = pd.read_csv(events_file, sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Order ID per thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 'warmup' 'Vir_N1_32_W1000_Def' 2000]\n",
      "[13 'stress' 'Vir_N1_32_W1000_Def' 2000]\n",
      "[17 'stress' 'Vir_N1_32_W1000_Def' 2000]\n",
      "[19 'stress' 'Vir_N1_32_W1000_Def' 2000]\n",
      "[20 'stress' 'Vir_N1_32_W1000_Def' 2000]\n",
      "[21 'stress' 'Vir_N1_32_W1000_Def' 2000]\n"
     ]
    }
   ],
   "source": [
    "df_filter_success = df[df['flag'] == 'SUCCESS']\n",
    "df_survival = df_filter_success.groupby(['thread_id', 'thread_type'], as_index=False)[['sim_id','order_id']].max()\n",
    "\n",
    "for line in df_survival.values:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a thread get the corresponding restriced df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_id</th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>order_id</th>\n",
       "      <th>number_of_results</th>\n",
       "      <th>runtime</th>\n",
       "      <th>flag</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sim_id, query_name, thread_id, thread_type, order_id, number_of_results, runtime, flag, correct]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[(df['thread_id'] == 16) & (df['thread_type'] == 'stress' )]  \n",
    "df_test2 = df_test[df_test['order_id'] <= 82] \n",
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preFilterForBMSurvival(filename):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    \n",
    "    df_filter_success = df[df['flag'] == 'SUCCESS']\n",
    "    df_survival = df_filter_success.groupby(['thread_id', 'thread_type'], as_index=False)[['sim_id','order_id']].max()\n",
    "\n",
    "    \n",
    "    restricted_dfs = []\n",
    "    for tup in df_survival.values:\n",
    "        thread_id = tup[0]\n",
    "        thread_type = tup[1]\n",
    "        df_thread = df[(df['thread_id'] == thread_id) & (df['thread_type'] == thread_type )]  \n",
    "        \n",
    "        max_order_id = tup[3]\n",
    "        df_thread_restricted = df_thread[df_thread['order_id'] <= max_order_id]\n",
    "        restricted_dfs.append(df_thread_restricted)\n",
    "    \n",
    "    return pd.concat(restricted_dfs, axis=0)\n",
    "        \n",
    "     \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = preFilterForBMSurvival(generateFilenameQueryEventsCorrect(('Virtuoso',1,32,'Watdiv1000M', 'Default','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 9)\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "print(12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timeouts, errors, successes column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 9)\n",
      "(4, 9)\n",
      "(11396, 9)\n",
      "(600, 9)\n",
      "(11396, 9)\n"
     ]
    }
   ],
   "source": [
    "TIMEOUT = df_test['flag'] == 'TIMEOUT'\n",
    "ERROR   = df_test['flag'] == 'ERROR'\n",
    "SUCCESS = df_test['flag'] == 'SUCCESS'\n",
    "CORRECT = df_test['correct'] == 'CORRECT'\n",
    "\n",
    "df_timeouts = df_test [TIMEOUT]\n",
    "df_errors = df_test [ERROR]\n",
    "df_successes = df_test [SUCCESS & CORRECT]\n",
    "df_incorrect = df_test [SUCCESS & ~CORRECT]\n",
    "\n",
    "df_nonerrors =  pd.concat([df_timeouts, df_successes])\n",
    "\n",
    "print(df_timeouts.shape)\n",
    "print(df_errors.shape)\n",
    "print(df_successes.shape)\n",
    "print(df_incorrect.shape)\n",
    "\n",
    "print(df_nonerrors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>timeouts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [query_name, thread_type, timeouts]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntimeouts = df_timeouts.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "ntimeouts = ntimeouts.rename(columns={'flag': 'timeouts'})\n",
    "ntimeouts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1/L1_split2.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L2/L2_split12.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2/S2_split19.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S4/S4_split7.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             query_name thread_type  errors\n",
       "0   L1/L1_split2.sparql      stress       1\n",
       "1  L2/L2_split12.sparql      stress       1\n",
       "2  S2/S2_split19.sparql      stress       1\n",
       "3   S4/S4_split7.sparql      stress       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerrors = df_errors.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "nerrors = nerrors.rename(columns={'flag': 'errors'})\n",
    "nerrors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1/C1_split0.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1/C1_split0.sparql</td>\n",
       "      <td>warmup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1/C1_split1.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1/C1_split1.sparql</td>\n",
       "      <td>warmup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1/C1_split10.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             query_name thread_type  success\n",
       "0   C1/C1_split0.sparql      stress        5\n",
       "1   C1/C1_split0.sparql      warmup        1\n",
       "2   C1/C1_split1.sparql      stress        5\n",
       "3   C1/C1_split1.sparql      warmup        1\n",
       "4  C1/C1_split10.sparql      stress        5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsuccess = df_successes.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "nsuccess = nsuccess.rename(columns={'flag': 'success'})\n",
    "nsuccess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C3/C3_split0.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C3/C3_split0.sparql</td>\n",
       "      <td>warmup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C3/C3_split1.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C3/C3_split1.sparql</td>\n",
       "      <td>warmup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C3/C3_split10.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             query_name thread_type  incorrect\n",
       "0   C3/C3_split0.sparql      stress          5\n",
       "1   C3/C3_split0.sparql      warmup          1\n",
       "2   C3/C3_split1.sparql      stress          5\n",
       "3   C3/C3_split1.sparql      warmup          1\n",
       "4  C3/C3_split10.sparql      stress          5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nincorrect = df_incorrect.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "nincorrect = nincorrect.rename(columns={'flag': 'incorrect'})\n",
    "nincorrect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runtime nonerror queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>median_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>S7/S7_split97.sparql</td>\n",
       "      <td>warmup</td>\n",
       "      <td>0.005846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>S7/S7_split98.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>12.211164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>S7/S7_split98.sparql</td>\n",
       "      <td>warmup</td>\n",
       "      <td>6.344599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>S7/S7_split99.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>0.008760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>S7/S7_split99.sparql</td>\n",
       "      <td>warmup</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                query_name thread_type  median_runtime\n",
       "3795  S7/S7_split97.sparql      warmup        0.005846\n",
       "3796  S7/S7_split98.sparql      stress       12.211164\n",
       "3797  S7/S7_split98.sparql      warmup        6.344599\n",
       "3798  S7/S7_split99.sparql      stress        0.008760\n",
       "3799  S7/S7_split99.sparql      warmup        0.005399"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonerror_timings = df_nonerrors.groupby(['query_name', 'thread_type'], as_index=False).agg({'runtime': np.median})\n",
    "nonerror_timings = nonerror_timings.rename(columns={'runtime': 'median_runtime'})\n",
    "nonerror_timings.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeouts</th>\n",
       "      <th>query_name</th>\n",
       "      <th>thread_type</th>\n",
       "      <th>errors</th>\n",
       "      <th>success</th>\n",
       "      <th>median_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>L1/L1_split2.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>L2/L2_split12.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.595631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>S2/S2_split19.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.163735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>S4/S4_split7.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.075144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>C1/C1_split0.sparql</td>\n",
       "      <td>stress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>57.697063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timeouts            query_name thread_type  errors  success  median_runtime\n",
       "0       0.0   L1/L1_split2.sparql      stress     1.0        4        0.009956\n",
       "1       0.0  L2/L2_split12.sparql      stress     1.0        4        0.595631\n",
       "2       0.0  S2/S2_split19.sparql      stress     1.0        4        0.163735\n",
       "3       0.0   S4/S4_split7.sparql      stress     1.0        4        0.075144\n",
       "4       0.0   C1/C1_split0.sparql      stress     0.0        5       57.697063"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge1 = pd.merge(ntimeouts, nerrors, how='outer', on=['query_name','thread_type'])\n",
    "df_merge1 = df_merge1.fillna(0)\n",
    "df_merge2 = pd.merge(df_merge1, nsuccess, how='outer', on=['query_name','thread_type'])\n",
    "df_merge2 = df_merge2.fillna(0)\n",
    "\n",
    "#LEAVE OUT: incorrect queries are unusable for runtime comparisons!\n",
    "\n",
    "#df_merge3 = pd.merge(df_merge2, nincorrect, how='outer', on=['query_name','thread_type'])\n",
    "#df_merge3 = df_merge3.fillna(0)\n",
    "df_merge3 = df_merge2\n",
    "\n",
    "df_merge4 = pd.merge(df_merge3, nonerror_timings, how='outer', on=['query_name','thread_type'])\n",
    "timeout = 300\n",
    "df_merge4 = df_merge4.fillna(timeout)\n",
    "df_merge4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(df_merge4.columns)\n",
    "df_merge5 = df_merge4[['query_name', 'thread_type', 'errors', 'timeouts', 'success', 'median_runtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge5.to_csv('test_tquery.csv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query Runtime for all available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createQueryRuntimeDF(filename, querytimeout):\n",
    "    df_survival = preFilterForBMSurvival(filename)\n",
    "        \n",
    "    TIMEOUT = df_survival['flag'] == 'TIMEOUT'\n",
    "    ERROR   = df_survival['flag'] == 'ERROR'\n",
    "    SUCCESS = df_survival['flag'] == 'SUCCESS'\n",
    "    CORRECT = df_survival['correct'] == 'CORRECT'\n",
    "\n",
    "    df_timeouts  = df_survival [TIMEOUT]\n",
    "    df_errors    = df_survival [ERROR]\n",
    "    df_successes = df_survival [SUCCESS & CORRECT]\n",
    "    df_incorrect = df_survival [SUCCESS & ~CORRECT]\n",
    "\n",
    "    df_nonerrors =  pd.concat([df_timeouts, df_successes])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ntimeouts        = df_timeouts.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "    nerrors          = df_errors.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "    nsuccess         = df_successes.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "    nincorrect       = df_incorrect.groupby(['query_name', 'thread_type'], as_index=False).agg({'flag': np.size})\n",
    "    nonerror_timings = df_nonerrors.groupby(['query_name', 'thread_type'], as_index=False).agg({'runtime': np.median})\n",
    "    \n",
    "    ntimeouts        = ntimeouts.rename(columns={'flag': 'timeouts'})\n",
    "    nerrors          = nerrors.rename(columns={'flag': 'errors'})\n",
    "    nsuccess         = nsuccess.rename(columns={'flag': 'success'})\n",
    "    nincorrect       = nincorrect.rename(columns={'flag': 'incorrect'})\n",
    "    nonerror_timings = nonerror_timings.rename(columns={'runtime': 'median_runtime'})\n",
    " \n",
    "    df_merge1 = pd.merge(ntimeouts, nerrors, how='outer', on=['query_name','thread_type'])\n",
    "    df_merge1 = df_merge1.fillna(0)\n",
    "    df_merge2 = pd.merge(df_merge1, nsuccess, how='outer', on=['query_name','thread_type'])\n",
    "    df_merge2 = df_merge2.fillna(0)\n",
    "\n",
    "    #LEAVE OUT: incorrect queries are unusable for runtime comparisons!\n",
    "\n",
    "    #df_merge3 = pd.merge(df_merge2, nincorrect, how='outer', on=['query_name','thread_type'])\n",
    "    #df_merge3 = df_merge3.fillna(0)\n",
    "    df_merge3 = df_merge2\n",
    "\n",
    "    df_merge4 = pd.merge(df_merge3, nonerror_timings, how='outer', on=['query_name','thread_type'])\n",
    "    df_merge4 = df_merge4.fillna(querytimeout)\n",
    "    \n",
    "    return df_merge4[['query_name', 'thread_type', 'success', 'errors', 'timeouts', 'median_runtime']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Blazegraph Watdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def runtimes_for_stores(tuples, timeout):\n",
    "    start = time.time()\n",
    "    \n",
    "    for bm_tuple in bm_tuples:\n",
    "    \n",
    "        filename = generateFilenameQueryEventsCorrect(bm_tuple)\n",
    "\n",
    "        print(filename + \": \" + str(os.path.isfile(filename)))\n",
    "\n",
    "        if os.path.isfile(filename):\n",
    "\n",
    "            df = createQueryRuntimeDF(filename, timeout)\n",
    "            new_filename = generateFilenameRuntimesCorrect(bm_tuple)\n",
    "            df.to_csv(new_filename, sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "    print_elapsed(start)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/Blazegraph_N1_32_Watdiv10M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Blazegraph_N1_32_Watdiv100M_Default_queryevents_correct.csv: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdwitte/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1457: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  stride //= shape[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/Blazegraph_N1_32_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Blazegraph_N1_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Blazegraph_N1_64_Watdiv1000M_Optimized_queryevents_correct.csv: True\n",
      "0.4529082775115967 secs\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"Blazegraph\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Blazegraph\", 1, 64, \"Watdiv1000M\", \"Optimized\", \"\")]\n",
    "\n",
    "querytimeout = 300\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GraphDB Watdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/GraphDB_N1_32_Watdiv10M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/GraphDB_N1_32_Watdiv100M_Default_queryevents_correct.csv: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdwitte/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1457: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  stride //= shape[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/GraphDB_N1_32_Watdiv1000M_Default_queryevents_correct.csv: False\n",
      "./csv_correct/GraphDB_N1_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/GraphDB_N1_64_Watdiv1000M_Optimized_queryevents_correct.csv: True\n",
      "0.38358449935913086 secs\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"GraphDB\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"GraphDB\", 1, 64, \"Watdiv1000M\", \"Optimized\", \"\")]\n",
    "\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ES Watdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/ES_N1_32_Watdiv10M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/ES_N1_32_Watdiv100M_Default_queryevents_correct.csv: False\n",
      "./csv_correct/ES_N1_32_Watdiv1000M_Default_queryevents_correct.csv: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdwitte/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1457: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  stride //= shape[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/ES_N3_32_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/ES_N1_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "0.36228251457214355 secs\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"ES\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 3, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"ES\", 1, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    "\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Virtuoso Watdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/Virtuoso_N1_32_Watdiv10M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_32_Watdiv100M_Default_queryevents_correct.csv: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdwitte/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1457: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  stride //= shape[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/Virtuoso_N1_32_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_32_Watdiv1000M_Default_RERUN_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N3_32_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_64_Watdiv1000M_Optimized_queryevents_correct.csv: True\n",
      "0.691211462020874 secs\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"Virtuoso\", 1, 32, \"Watdiv10M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Watdiv1000M\", \"Default\", \"RERUN\"), \\\n",
    "(\"Virtuoso\", 3, 32, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Watdiv1000M\", \"Optimized\", \"\")]\n",
    "\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fuseki Watdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/Fuseki_N1_64_Watdiv100M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Fuseki_N1_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "0.08414578437805176 secs\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"Fuseki\", 1, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"Fuseki\", 1, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    "\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. LDF Watdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/LDF_N1_64_Watdiv100M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/LDF_N3_64_Watdiv100M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/LDF_N1_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/LDF_N3_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "0.21881604194641113 secs\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"LDF\", 1, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"LDF\", 3, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"LDF\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"LDF\", 3, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    "\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. FluidOps Watdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/FluidOps_N3_64_Watdiv100M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/FluidOps_N1_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "./csv_correct/FluidOps_N3_64_Watdiv1000M_Default_queryevents_correct.csv: True\n",
      "0.1184389591217041 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdwitte/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1457: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  stride //= shape[i]\n"
     ]
    }
   ],
   "source": [
    "bm_tuples = [ (\"FluidOps\", 3, 64, \"Watdiv100M\", \"Default\", \"\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Watdiv1000M\", \"Default\", \"\"), \\\n",
    "(\"FluidOps\", 3, 64, \"Watdiv1000M\", \"Default\", \"\")]\n",
    "\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Ontoforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./csv_correct/Blazegraph_N1_64_Ontoforce_Optimized_queryevents_correct.csv: True\n",
      "./csv_correct/GraphDB_N1_64_Ontoforce_Optimized_queryevents_correct.csv: True\n",
      "./csv_correct/ES_N1_64_Ontoforce_Default_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_64_Ontoforce_Optimized_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_64_Ontoforce_Optimized_VWall_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_32_Ontoforce_Optimized_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N1_32_Ontoforce_Optimized_VWall_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N3_64_Ontoforce_Optimized_0_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N3_64_Ontoforce_Optimized_1_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N3_64_Ontoforce_Optimized_2_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N3_64_Ontoforce_Optimized_AWS1_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N3_64_Ontoforce_Optimized_AWS2_queryevents_correct.csv: True\n",
      "./csv_correct/Virtuoso_N3_64_Ontoforce_Optimized_AWS3_queryevents_correct.csv: True\n",
      "./csv_correct/Fuseki_N1_64_Ontoforce_Default_queryevents_correct.csv: True\n",
      "./csv_correct/FluidOps_N1_64_Ontoforce_Default_1_queryevents_correct.csv: True\n",
      "./csv_correct/FluidOps_N1_64_Ontoforce_Default_2_queryevents_correct.csv: True\n",
      "./csv_correct/FluidOps_N1_64_Ontoforce_Default_3_queryevents_correct.csv: True\n",
      "./csv_correct/FluidOps_N3_64_Ontoforce_Default_1_queryevents_correct.csv: True\n",
      "./csv_correct/FluidOps_N3_64_Ontoforce_Default_2_queryevents_correct.csv: True\n",
      "1.1684279441833496 secs\n"
     ]
    }
   ],
   "source": [
    "querytimeout = 1200\n",
    "bm_tuples = [ (\"Blazegraph\", 1, 64, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"GraphDB\", 1, 64, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"ES\", 1, 64, \"Ontoforce\", \"Default\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 64, \"Ontoforce\", \"Optimized\", \"VWall\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Ontoforce\", \"Optimized\", \"\"), \\\n",
    "(\"Virtuoso\", 1, 32, \"Ontoforce\", \"Optimized\", \"VWall\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"0\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"1\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"2\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"AWS1\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"AWS2\"), \\\n",
    "(\"Virtuoso\", 3, 64, \"Ontoforce\", \"Optimized\", \"AWS3\"), \\\n",
    "(\"Fuseki\", 1, 64, \"Ontoforce\", \"Default\", \"\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Ontoforce\", \"Default\", \"1\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Ontoforce\", \"Default\", \"2\"), \\\n",
    "(\"FluidOps\", 1, 64, \"Ontoforce\", \"Default\", \"3\"), \\\n",
    "(\"FluidOps\", 3, 64, \"Ontoforce\", \"Default\", \"1\"), \\\n",
    "(\"FluidOps\", 3, 64, \"Ontoforce\", \"Default\", \"2\")]\n",
    "#omitted default 3 since all queries failed\n",
    "\n",
    "runtimes_for_stores(bm_tuples, querytimeout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Runtime dataframe from results file: Tryout\n",
    "\n",
    "* for two simulations (early on in bm cycle) the log files were not stored:\n",
    "    - GraphDB,1,32,Watdiv1000M,Default\n",
    "    - ES     ,1,32,Watdiv100M ,Default\n",
    "    \n",
    "* Let's manually convert them to the queryruntimes.csv format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm_tuple1 = ('GraphDB',1,32,'Watdiv1000M','Default','')\n",
    "results_csv = './GraphDB/results_GraphDB_N1_32_Watdiv1000M_Default.csv'\n",
    "df_tuple1 = pd.read_csv(results_csv, sep=',', skiprows=34)\n",
    "\n",
    "interesting_cols = ['Operation', 'Average Runtime (Arithmetic)']\n",
    "df_tuple1 = df_tuple1[interesting_cols]\n",
    "\n",
    "df_tuple1['query_name'] = df_tuple1['Operation'].apply(lambda op: op[len('templated/'):])\n",
    "df_tuple1['median_runtime'] = df_tuple1['Average Runtime (Arithmetic)']\n",
    "df_tuple1['thread_type'] = 'stress'\n",
    "\n",
    "df_tuple1['success'] = 1\n",
    "df_tuple1['errors'] = 0\n",
    "df_tuple1['timeouts'] = 0\n",
    "\n",
    "interesting_cols = ['query_name', 'thread_type', 'success', 'errors', 'timeouts', 'median_runtime']\n",
    "df_tuple2 = df_tuple1[interesting_cols]\n",
    "\n",
    "new_filename = generateFilenameRuntimesCorrect(bm_tuple1)\n",
    "df_tuple2.to_csv(new_filename, sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm_tuple1 = ('ES',1,32,'Watdiv100M','Default','')\n",
    "results_csv = './ES/results_ES_N1_32_Watdiv100M_Default.csv'\n",
    "\n",
    "interesting_cols = ['Operation', 'Average Runtime (Arithmetic)']\n",
    "df_tuple1 = df_tuple1[interesting_cols]\n",
    "\n",
    "df_tuple1['query_name'] = df_tuple1['Operation'].apply(lambda op: op[len('templated/'):])\n",
    "df_tuple1['median_runtime'] = df_tuple1['Average Runtime (Arithmetic)']\n",
    "df_tuple1['thread_type'] = 'stress'\n",
    "\n",
    "df_tuple1['success'] = 1\n",
    "df_tuple1['errors'] = 0\n",
    "df_tuple1['timeouts'] = 0\n",
    "\n",
    "interesting_cols = ['query_name', 'thread_type', 'success', 'errors', 'timeouts', 'median_runtime']\n",
    "df_tuple2 = df_tuple1[interesting_cols]\n",
    "\n",
    "new_filename = generateFilenameRuntimesCorrect(bm_tuple1)\n",
    "df_tuple2.to_csv(new_filename, sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
